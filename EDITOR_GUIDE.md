# Content Editor Guide
**HMH Multi-Curriculum Knowledge Base - For Content Editors**
**Version:** 1.0
**Last Updated:** November 6, 2025

---

## Welcome to the Editorial Team

As a content editor, you ensure authored content meets quality standards before publication. You are the **quality gate** between draft content and published materials.

Your reviews maintain consistency, pedagogical soundness, and compliance across all HMH educational products.

---

## Table of Contents

**Quick Start:**
- [Your First Week as an Editor](#your-first-week-as-an-editor)

**Core Content:**
1. [Getting Started](#1-getting-started)
2. [Editorial Workflow](#2-editorial-workflow)
3. [Content Review Checklist](#3-content-review-checklist)
4. [Providing Effective Feedback](#4-providing-effective-feedback)
5. [Approval Process](#5-approval-process)
6. [Common Issues and Fixes](#6-common-issues-and-fixes)
7. [Complete Review Examples](#7-complete-review-examples)

**Advanced Topics:**
8. [Difficult Conversations and Author Management](#8-difficult-conversations-and-author-management)
9. [State Compliance Deep Dives](#9-state-compliance-deep-dives)
10. [Editor Self-Review and Calibration](#10-editor-self-review-and-calibration)
11. [Workload and Time Management](#11-workload-and-time-management)

**Support:**
12. [Frequently Asked Questions](#12-frequently-asked-questions)
13. [Troubleshooting Common Challenges](#13-troubleshooting-common-challenges)

---

## Your First Week as an Editor

**New to content editing?** This quickstart gets you confident and productive in 5 days.

### Day 1: Shadow and Observe (6-8 hours)

**Morning: Orientation (2-3 hours)**
1. **Review documentation**
   - Read this guide (Sections 1-2)
   - Skim AUTHOR_GUIDE.md to understand author perspective
   - Review one approved lesson example (Section 7)

2. **Set up your tools**
   - GitHub access confirmed
   - Knowledge base repository cloned
   - Editorial checklist printed or bookmarked
   - Style guides accessible

3. **Meet your team**
   - Your mentor/supervisor
   - Other editors (calibration partners)
   - Curriculum leads you'll work with
   - Sample authors (if available)

**Afternoon: Shadow Experienced Editor (3-4 hours)**
1. **Observe a live review**
   - Watch experienced editor review content
   - Ask questions about decision-making
   - See how they use knowledge base files
   - Observe GitHub commenting workflow

2. **Review completed PRs**
   - Read 2-3 approved content pieces with editorial comments
   - Read 2-3 "requires revision" pieces with feedback
   - Note patterns in what gets flagged
   - Compare editor comments across reviewers

**Day 1 Goals:**
- [ ] Tools set up and working
- [ ] Documentation read (Sections 1-2)
- [ ] Shadowed at least one complete review
- [ ] Reviewed 4+ completed PRs with comments

---

### Day 2: Practice Review (Non-Live) (6-8 hours)

**Morning: Practice Review #1 - Approved Content (3-4 hours)**
1. **Select already-approved lesson**
   - Choose lesson from `/published/` that was approved 1-2 months ago
   - Pretend you're seeing it for first time

2. **Conduct full review**
   - Use Editorial Checklist (Section 3)
   - Write comments as if this were live
   - Note what you'd flag, what you'd approve
   - Time yourself (should take 1-3 hours)

3. **Compare to actual editorial comments**
   - Find the original PR with editor feedback
   - What did you catch that editor caught?
   - What did you miss?
   - What did you flag that editor didn't?
   - Discuss differences with mentor

**Afternoon: Practice Review #2 - Content That Needed Revision (3-4 hours)**
1. **Select content that required revisions**
   - Find PR where editor requested changes (before author fixed)
   - Review the original submission

2. **Write your practice feedback**
   - What issues do you see?
   - Write full feedback using templates (Section 4)
   - Prioritize required vs suggested changes

3. **Compare to actual editorial feedback**
   - How does your feedback compare?
   - Did you identify the same issues?
   - Was your feedback as specific?
   - Discuss with mentor

**Day 2 Goals:**
- [ ] Completed 2 practice reviews
- [ ] Compared your judgment to experienced editors
- [ ] Identified your knowledge gaps
- [ ] Comfortable with checklist and templates

---

### Day 3: First Live Review - With Support (6-8 hours)

**Morning: Preparation (1-2 hours)**
1. **Receive your first real assignment**
   - Simple lesson (not complex assessment)
   - Familiar grade level and subject
   - Reasonable timeline (not urgent)

2. **Prepare for review**
   - Read content brief
   - Identify curriculum config
   - Gather relevant KB files
   - Review similar approved content

**Afternoon: Conduct Review (3-5 hours)**
1. **Preliminary review** (Step 2 workflow)
   - Check completeness
   - Note obvious issues

2. **Detailed review** (Step 3 workflow)
   - Use checklist methodically
   - Document every issue
   - Reference KB files for verification
   - Take notes, don't rush

3. **Draft feedback** (Step 4 workflow)
   - Use template
   - Be specific and actionable
   - Include references
   - **Don't submit yet**

**Evening: Review with Mentor (1 hour)**
1. **Walk through your review**
   - Show what you flagged
   - Explain your reasoning
   - Get mentor feedback on your feedback

2. **Revise your comments**
   - Incorporate mentor suggestions
   - Clarify anything vague
   - Ensure specificity

3. **Submit feedback**
   - Post comments to PR
   - Notify author
   - Set up alerts for author response

**Day 3 Goals:**
- [ ] Completed first live review with mentor oversight
- [ ] Posted feedback to real PR
- [ ] Learned from mentor's expertise
- [ ] Built confidence in judgment

---

### Day 4: Second Live Review - More Independent (6-8 hours)

**Morning: Second Assignment (4-5 hours)**
1. **Receive second assignment**
   - Slightly more complex content
   - Work more independently
   - Mentor available for questions

2. **Conduct review**
   - Follow workflow (Section 2)
   - Use checklist (Section 3)
   - Draft feedback (Section 4)

3. **Self-check before submitting**
   - Did I verify against KB files?
   - Is my feedback specific and actionable?
   - Did I balance critical and positive?
   - Did I prioritize required vs suggested?

4. **Quick mentor check**
   - 15-minute review of your feedback
   - Submit with confidence

**Afternoon: Handle Author Response (2-3 hours)**
1. **If author has questions on Day 3 review**
   - Respond promptly
   - Clarify your feedback
   - Be collaborative, not defensive

2. **Learn about author perspectives**
   - Some authors need more hand-holding
   - Some authors are experienced and efficient
   - Adjust communication style accordingly

3. **Start third assignment if ready**
   - Or continue learning from completed PRs

**Day 4 Goals:**
- [ ] Completed second live review with minimal help
- [ ] Responded to author questions professionally
- [ ] Understanding different author styles
- [ ] Feeling more confident

---

### Day 5: Establish Rhythm (6-8 hours)

**Morning: Third Assignment (3-4 hours)**
1. **Take on slightly challenging content**
   - Different subject or grade level
   - Or assessment instead of lesson
   - Build your range

2. **Work independently**
   - Mentor on standby for questions only
   - Make decisions confidently
   - Trust your judgment

**Afternoon: Reflect and Plan (2-3 hours)**
1. **Review your Week 1 work**
   - How did your reviews go?
   - What are you strong at?
   - Where do you need to improve?
   - What questions remain?

2. **Set Week 2 goals with mentor**
   - How many reviews per week?
   - What content types to focus on?
   - What skills to develop?
   - What resources to study?

3. **Study one knowledge domain deeply**
   - Pick one area: Standards alignment, ELPS, MLRs, UDL, etc.
   - Read all relevant KB files thoroughly
   - Review multiple examples of that aspect
   - Become expert in one area

**Week 1 Wrap-Up Meeting (1 hour)**
- Debrief with mentor/supervisor
- Celebrate successes
- Identify growth areas
- Set Week 2-4 learning goals

**Day 5 Goals:**
- [ ] Completed third assignment independently
- [ ] Reflected on Week 1 learning
- [ ] Set clear goals for Week 2+
- [ ] Identified expertise area to develop

---

### What to Expect: Weeks 2-4

**Week 2: Building Confidence**
- 3-5 reviews per week
- Mix of content types
- Mentor check-ins reduce to 1-2x/week
- Start participating in calibration sessions

**Week 3: Increasing Independence**
- 5-7 reviews per week
- More complex assignments
- Handling revision cycles independently
- Contributing to editor discussions

**Week 4: Full Productivity**
- 7-10 reviews per week (depending on organization)
- All content types
- Minimal mentor oversight
- Mentoring newer editors (shadowing)

**Typical Learning Curve:**
- Week 1: 2-3 reviews (with support)
- Week 2: 3-5 reviews
- Week 3: 5-7 reviews
- Week 4+: 7-10 reviews
- Month 3+: 10-15 reviews per week

**Common First-Month Challenges:**
1. **Imposter syndrome** - "I don't know enough to judge this"
   - Normal! Every editor feels this
   - Knowledge base files are your safety net
   - Ask questions early and often

2. **Too slow** - Reviews take 4+ hours
   - Speed comes with practice
   - You'll recognize patterns
   - Templates speed up feedback writing

3. **Too harsh or too lenient** - Unsure of standards
   - Calibration sessions help
   - Compare to other editors' decisions
   - Mentor feedback adjusts your judgment

4. **Author pushback** - "But I spent days on this!"
   - Stay professional and collaborative
   - Focus on standards, not effort
   - See Section 8 for guidance

---

### First Week Checklist

**By end of Week 1, you should have:**
- [ ] Completed 2-3 live reviews
- [ ] Posted feedback to real PRs
- [ ] Responded to at least one author question
- [ ] Read Sections 1-6 of this guide thoroughly
- [ ] Reviewed 6+ examples of approved/revised content
- [ ] Met your editorial team
- [ ] Set up all tools and access
- [ ] Identified one expertise area to develop
- [ ] Received mentor feedback on your work
- [ ] Felt progressively more confident each day

---

### Resources for Your First Week

**Must-Read Documentation:**
- EDITOR_GUIDE.md Sections 1-6 (this guide)
- AUTHOR_GUIDE.md Sections 1-4 (understand author perspective)
- One complete example from Section 7 (see what "good" looks like)

**Practice Materials:**
- 4-6 already-approved content pieces
- 4-6 "required revisions" PRs (before and after)
- Your state's compliance KB files

**People to Connect With:**
- Your assigned mentor
- 2-3 other editors (calibration partners)
- 1-2 experienced authors (optional, but helpful)
- Curriculum lead for your primary subject

**Reminders:**
- ✅ Ask questions constantly - no stupid questions
- ✅ Use knowledge base files - they're your authority
- ✅ Compare to approved examples when unsure
- ✅ Be gentle with yourself - learning takes time
- ✅ Focus on learning, not speed, in Week 1

---

## 1. Getting Started

### Your Responsibilities

**Content Review:**
- Verify standards alignment
- Check pedagogical soundness
- Ensure accessibility compliance
- Validate cultural responsiveness
- Confirm state compliance

**Feedback and Communication:**
- Provide clear, actionable feedback
- Explain rationale for changes
- Collaborate to improve quality
- Approve when standards met

**Process Management:**
- Track content through review cycles
- Enforce deadlines
- Escalate issues when needed
- Maintain consistency

### Your Tools

1. **Editorial Checklist** - Standardized review criteria (Section 3)
2. **Knowledge Base** - Reference for standards (`/reference/hmh-knowledge-v2/`)
3. **GitHub** - Review, comments, approval workflow
4. **Style Guides** - HMH editorial standards

### Workflow Overview

```
1. Author submits (Pull Request)
   ↓
2. Editor receives notification
   ↓
3. Editor reviews using checklist
   ↓
4. Editor provides feedback
   ↓
5. Author revises
   ↓
6. Editor re-reviews
   ↓
7. Approve and merge OR return to step 4
```

---

## 2. Editorial Workflow

### Step 1: Receive Assignment

**Notification Methods:**
- Author tags you in pull request
- Content team assigns review
- GitHub notification

**Initial Actions:**
- [ ] Review PR description
- [ ] Check content brief
- [ ] Identify curriculum config
- [ ] Note timeline/deadline
- [ ] Acknowledge receipt

### Step 2: Preliminary Review (15-30 min)

**Quick Scan:**
- [ ] All required files present?
- [ ] Follows template structure?
- [ ] Length appropriate?
- [ ] Obvious errors?

**If Major Issues:**
- Return to author immediately
- Provide high-level feedback
- Example: "Missing answer key" or "Wrong grade level"

**If Passes:**
- Proceed to detailed review

### Step 3: Detailed Review (1-3 hours)

**Use Editorial Checklist** (Section 3)

Review across 7 quality pillars:
1. Standards Alignment
2. Pedagogical Soundness
3. Language Support
4. UDL
5. Accessibility
6. Cultural Responsiveness
7. State Compliance

**Document Findings:**
- Leave specific comments in GitHub
- Use line-by-line comments for specific issues
- Use general comments for big-picture feedback
- Mark status: "Requires Changes" or "Approved"

### Step 4: Provide Feedback (30-60 min)

**Effective Feedback:**
- **Specific:** "Add alt text to Figure 3" not "Fix images"
- **Actionable:** "Change sentence frame to ___" not "Needs work"
- **Constructive:** Explain why
- **Prioritized:** Critical vs. optional

**Template:**
```markdown
## Review Summary

**Status:** Requires Revisions / Approved with Minor Changes / Approved

**Strengths:**
- [Positive aspect 1]
- [Positive aspect 2]

**Required Changes:**
1. [Critical issue with explanation]
2. [Critical issue with explanation]

**Suggested Changes:**
1. [Optional improvement]
2. [Optional improvement]

**Questions:**
- [Clarification needed]
```

### Step 5: Author Revises

- Author receives feedback
- Author makes revisions
- Author responds to comments
- Author pushes updated version

**Your Role:**
- Answer questions promptly
- Clarify feedback if unclear
- Be available for consultation

### Step 6: Re-Review (30-60 min)

**Focus:**
- Did author address required changes?
- Are revisions acceptable?
- Any new issues introduced?

**Outcomes:**
- **Approved:** Merge PR
- **More Revisions:** Focused feedback, return to Step 5
- **Escalate:** If issues persist after 2-3 cycles

### Step 7: Approval and Merge

**When standards met:**
- [ ] Leave approval comment
- [ ] Change PR status to "Approved"
- [ ] Merge pull request
- [ ] Content moves to `/published/`
- [ ] Thank author

---

## 3. Content Review Checklist

### Section 1: Standards Alignment

**How to Review:**

1. **Open the content brief** - Note all standards listed (e.g., TEKS.5.3.A, CCSS.MATH.5.NF.A.1)
2. **Open the standards alignment KB file** for that state/subject:
   - Texas Math: `/subjects/mathematics/districts/texas/teks-math-alignment.md`
   - California Math: `/subjects/mathematics/common/ccss-m-alignment.md`
   - Florida Math: `/subjects/mathematics/districts/florida/mafs-alignment.md`
   - ELA/Science: Similar pattern
3. **For each standard listed in the content:**
   - Find the standard in the KB file
   - Read the complete standard description
   - Verify the learning objective verb matches the standard's cognitive demand
   - Check that practice problems/activities match the standard's depth and rigor
   - Confirm examples align with the standard's intent
4. **Check vertical alignment** - Look at grade before/after in KB file:
   - Does this lesson build on prior grade knowledge?
   - Does it prepare for next grade expectations?
5. **Verify assessment alignment**:
   - Each assessment item must test a standard from the lesson
   - Item DOK level should match standard expectation (check `/universal/frameworks/dok-framework.md`)
   - No items testing skills not explicitly taught

**Standards Addressed:**
- [ ] All standards from brief addressed
- [ ] No extraneous standards
- [ ] Standards correctly interpreted (check KB alignment file)
- [ ] Depth appropriate

**Learning Objectives:**
- [ ] Measurable (Bloom's Taxonomy verbs)
- [ ] Map directly to standards
- [ ] Student-facing ("Students will...")
- [ ] Grade-appropriate

**Assessment Alignment:**
- [ ] Assessments measure objectives/standards
- [ ] Doesn't test unrelated skills
- [ ] DOK level matches standard

**Reference:**
- `/subjects/[subject]/districts/[state]/[standards-file].md`
- `/universal/frameworks/dok-framework.md`

---

### Section 2: Pedagogical Soundness

**How to Review:**

1. **Check instructional sequence structure:**
   - Trace the flow: Warm-up → Direct Instruction → Guided Practice → Independent Practice → Closure
   - At each phase, ask: "Does this follow gradual release?" (I do → We do → You do)
   - Verify warm-up connects to prior knowledge (not random)
   - Confirm closure checks understanding (not just "clean up")

2. **Verify instructional routines** (if used):
   - **For MLRs** (Math): Open `/subjects/mathematics/common/mlr/mlr[X]-[name].md`
     - Check: Are all protocol steps present? Is timing reasonable? Are facilitation notes clear?
     - Example: MLR8 must have explicit discussion supports, not just "discuss"
   - **For Literacy Routines** (ELA): Open `/subjects/ela/common/[routine-name].md`
     - Close Reading: 3 reads present (literal, craft, inference)?
     - Think-Pair-Share: All 3 phases structured with clear transitions?
   - **For Science Practices**: Open `/subjects/science/common/science-practices-framework.md`
     - Which of the 8 SEPs is being used? Is it applied correctly?

3. **Check formative assessment:**
   - Count checks: Should be every 10-15 minutes
   - Variety: Exit tickets, whiteboards, thumbs up, partner checks, observation notes
   - Are there clear success criteria for each check?
   - Does teacher know what to do if students struggle? (reteaching strategy noted?)

4. **Look for misconceptions:**
   - Are common misconceptions anticipated? (Check subject KB files for lists)
   - Are strategies to address them provided?
   - Do examples and non-examples help clarify?

5. **Evaluate differentiation:**
   - Three levels present? (Below grade, On grade, Above grade)
   - Are scaffolds specific? ("Use manipulatives" not enough - which ones, how?)
   - Do extensions provide genuine challenge? (Not just "more problems")

**Instructional Sequence:**
- [ ] Gradual release (I do, We do, You do)
- [ ] Warm-up activates prior knowledge
- [ ] Direct instruction includes modeling
- [ ] Guided practice scaffolded
- [ ] Independent practice individual
- [ ] Closure summarizes and checks understanding

**Instructional Routines:**
- [ ] Routine applied correctly (check KB file)
- [ ] All steps present
- [ ] Timing appropriate
- [ ] Facilitation notes clear

**Example Checks for MLRs:**
- [ ] MLR1: 3 rounds of "Stronger and Clearer Each Time"
- [ ] MLR2: Clear protocol for collecting/displaying language
- [ ] MLR8: Discussion supports explicitly taught

**Example Checks for Literacy Routines:**
- [ ] Close Reading: 3 reads present (literal, craft, inference)
- [ ] Think-Pair-Share: All 3 phases structured
- [ ] Annotation: Symbol system introduced

**Formative Assessment:**
- [ ] Checks every 10-15 minutes
- [ ] Multiple check types
- [ ] Clear success criteria
- [ ] Notes on responding to errors

**Misconceptions:**
- [ ] Common misconceptions anticipated
- [ ] Strategies to address provided
- [ ] Examples and non-examples clarify

**Differentiation:**
- [ ] Three levels: Below, On, Above
- [ ] Scaffolds specific and appropriate
- [ ] Extensions provide genuine challenge

**Reference:**
- `/subjects/mathematics/common/mlr/*.md`
- `/subjects/ela/common/literacy-routines/*.md`
- `/subjects/science/common/science-practices-framework.md`

---

### Section 3: Language Support

**How to Review:**

1. **Identify required language standards** based on state:
   - Texas: ELPS (English Language Proficiency Standards)
   - California: ELD (English Language Development Standards)
   - Florida: ESOL/WIDA Standards
   - Open the appropriate file: `/districts/[state]/language/[framework]-alignment.md`

2. **Check scaffolding for three proficiency levels:**
   - **Beginning/Bridging**: Should have heavy visuals, simplified language, sentence frames, reduced output expectations
   - **Intermediate**: Should have sentence frames, visual support, vocabulary scaffolds, structured partner work
   - **Advanced/Reaching**: Should have academic language frames, vocabulary extensions, discourse structures
   - Ask: "Could a teacher implement this scaffold without guessing?"

3. **Verify sentence frames:**
   - Are frames provided for academic discourse? (explaining, justifying, comparing, concluding)
   - Do frames match the language function? (Not just "I think ___")
   - Check `/universal/frameworks/sentence-frames-library.md` for appropriate frames
   - Are frames integrated into activities (not just listed at bottom)?

4. **Check vocabulary support:**
   - Is key academic vocabulary explicitly identified?
   - Is vocabulary taught (not just mentioned)?
   - Are visual supports provided? (images, diagrams, realia)
   - Is there a glossary or word wall?

5. **Look for language routines integration:**
   - For Math: Are MLRs used to support language development?
   - Are partner/group structures used strategically for language practice?
   - Is output scaffolded (listen → speak → read → write progression)?

**Standards Addressed:**
- [ ] ELPS/ELD/ESOL standards addressed
- [ ] All 4 domains if applicable (Listening, Speaking, Reading, Writing)

**Scaffolds for Emergent Bilinguals:**
- [ ] Differentiated for Beginning, Intermediate, Advanced
- [ ] Beginning: Heavy visual, sentence frames, simplified language
- [ ] Intermediate: Sentence frames, visual support, vocabulary
- [ ] Advanced: Academic discourse frames, vocabulary

**Sentence Frames:**
- [ ] Provided for academic discourse
- [ ] From sentence frames library (or equivalent)
- [ ] Match language function (explaining, justifying, comparing)

**Vocabulary:**
- [ ] Key academic vocabulary identified
- [ ] Explicitly taught (not assumed)
- [ ] Visual supports provided
- [ ] Glossary or word wall included

**Language Routines:**
- [ ] MLRs used (math)
- [ ] Partner/group structures support language
- [ ] Strategic grouping for practice

**Reference:**
- `/districts/texas/language/elps-alignment.md`
- `/districts/california/language/eld-alignment.md`
- `/districts/florida/language/esol-alignment.md`
- `/universal/frameworks/eb-scaffolding-guide.md`
- `/universal/frameworks/sentence-frames-library.md`

---

### Section 4: UDL

**How to Review:**

1. **Open UDL reference:** `/universal/frameworks/udl-principles-guide.md`

2. **Check Representation (How information is presented):**
   - Count modalities: Are concepts presented in at least 2 ways?
   - Examples: Visual + verbal, diagram + text, video + transcript, model + explanation
   - Are visual supports provided for abstract concepts?
   - Can students perceive information in multiple ways?

3. **Check Action/Expression (How students demonstrate learning):**
   - Are there options for how students show understanding?
   - Examples: Can students respond verbally, in writing, through drawing, by building a model?
   - Are assistive tools/supports mentioned? (manipulatives, sentence frames, graphic organizers)
   - Look specifically at independent practice and assessments

4. **Check Engagement (How students are motivated):**
   - Does content connect to students' lives and interests?
   - Are there options for different challenge levels?
   - Is choice embedded where appropriate? (choice of problem contexts, choice of strategy)
   - Does content provide relevance and authentic purpose?

5. **UDL Red Flags:**
   - Only one way to learn (lecture only, text only)
   - Only one way to demonstrate (written test only)
   - No connections to student experience
   - No scaffolds or supports offered

**Multiple Means of Representation:**
- [ ] Concepts in ≥ 2 modalities (visual + verbal, etc.)
- [ ] Visual supports for key concepts
- [ ] Options for perception

**Multiple Means of Action/Expression:**
- [ ] Student choices in demonstrating learning
- [ ] Options: verbal, written, drawn, modeled
- [ ] Tools/supports accessible

**Multiple Means of Engagement:**
- [ ] Connects to students' lives
- [ ] Options for different challenge levels
- [ ] Choice embedded where appropriate

**Reference:** `/universal/frameworks/udl-principles-guide.md`

---

### Section 5: Accessibility

**How to Review:**

1. **Open accessibility reference:** `/universal/accessibility/wcag-compliance-guide.md`

2. **Check every image:**
   - Does each image have alt text? (Required for WCAG 2.1 SC 1.1.1)
   - Is alt text descriptive? (Not just "image" or "figure 1")
   - Test: Close your eyes, listen to alt text - can you understand the content?
   - Complex images (graphs, diagrams): Is there an extended description?
   - Decorative images: Are they marked as decorative (empty alt="")?

3. **Check color and contrast:**
   - Use [WebAIM Contrast Checker](https://webaim.org/resources/contrastchecker/)
   - Normal text: Contrast ratio ≥ 4.5:1 required
   - Large text (18pt+ or 14pt+ bold): Contrast ratio ≥ 3:1 required
   - Is information conveyed by color alone? (Red/green for right/wrong - FAIL)
   - Must have additional indicator (checkmark/X, bold, text label)

4. **Check document structure:**
   - Are headings properly nested? (H1 → H2 → H3, no skipping)
   - Do lists use proper markup? (bullets, numbers, not just hyphens)
   - Do tables have headers? (First row identifies columns)
   - Are links descriptive? ("Click here" - FAIL; "View rubric" - PASS)

5. **Check interactivity:**
   - Can all interactive elements be accessed by keyboard? (No mouse-only)
   - Do forms have labels? (Not just placeholder text)
   - Is there any flashing/blinking content? (Seizure risk - max 3 flashes/second)

6. **Check text readability:**
   - Is text selectable and scalable? (Not embedded in images)
   - Font size ≥ 12pt?
   - Line spacing ≥ 1.5x font size?

7. **Use automated tools** (when available):
   - [WAVE Tool](https://wave.webaim.org/) for web content
   - Note: Tools catch ~30% of issues - manual review critical

**Images:**
- [ ] Every image has descriptive alt text
- [ ] Alt text describes content and function
- [ ] Complex images have extended descriptions
- [ ] Decorative images marked

**Color and Contrast:**
- [ ] Contrast ratio ≥ 4.5:1 (normal text)
- [ ] Contrast ratio ≥ 3:1 (large text)
- [ ] Information not conveyed by color alone

**Structure:**
- [ ] Headings properly nested (H1 → H2 → H3)
- [ ] Lists use proper markup
- [ ] Tables have headers
- [ ] Links descriptive

**Interactivity:**
- [ ] Keyboard-accessible
- [ ] Forms have labels
- [ ] No flashing content

**Text:**
- [ ] Selectable and scalable
- [ ] Font size ≥ 12pt
- [ ] Line spacing ≥ 1.5x

**Tools:**
- [WebAIM Contrast Checker](https://webaim.org/resources/contrastchecker/)
- [WAVE Tool](https://wave.webaim.org/)

**Reference:** `/universal/accessibility/wcag-compliance-guide.md`

---

### Section 6: Cultural Responsiveness

**How to Review:**

1. **Open CEID reference:** `/universal/content-equity/ceid-guidelines.md`

2. **Check representation across content:**
   - List all names used: Are they diverse? (Not all European names)
   - Count images of people: Do they show diversity across race, ability, age, body type?
   - List family structures mentioned: Nuclear family, single parent, multigenerational, two moms/dads, guardians?
   - Economic contexts: Do examples assume wealth? (Ski vacation, beach house, eating out frequently)

3. **Screen for stereotypes using CEID 11 categories:**
   - **Gender**: Are roles stereotypical? (Mom cooks, dad works on car - FAIL)
   - **Race/Ethnicity**: Are characters tokenized? (Only minority character needs help - FAIL)
   - **Ability**: Is disability portrayed positively? (Wheelchair user as inspiration - problematic)
   - **Socioeconomic**: Are poor people pitied? Are wealthy people the default?
   - **Family**: Is nuclear family assumed? (Take-home note "Have your parents sign" - assume 2 parents)
   - **Regional**: Geographic assumptions? (Everyone has a yard, everyone lives in suburbs)
   - **Language**: Is multilingualism valued? Or is English assumed?
   - **Religious**: Is content secular and inclusive? (Christmas vs winter holidays)
   - **Age**: Are older adults portrayed positively?
   - **Body Type**: Are all body types represented?
   - **Sexual Orientation**: Are diverse families included naturally?

4. **Check contexts and scenarios:**
   - Do contexts reflect diverse experiences?
   - Are scenarios culturally inclusive? (Not everyone celebrates birthdays, not everyone has pets)
   - Do examples avoid assumptions about background knowledge?

5. **Apply "Would this alienate?" test:**
   - Would a student from [demographic] feel excluded or stereotyped?
   - Test across: Low-income, immigrant, multilingual, disability, LGBTQ+ family, non-Christian

6. **Look for authenticity, not tokenism:**
   - Is diversity natural or forced?
   - Are diverse characters full characters or just "diversity checkboxes"?

**Representation:**
- [ ] Diverse names (multiple cultures)
- [ ] Varied family structures
- [ ] Diverse economic contexts
- [ ] Images show diverse people

**Stereotypes:**
- [ ] No gender stereotypes
- [ ] No racial/ethnic stereotypes
- [ ] No ability stereotypes
- [ ] No family structure stereotypes
- [ ] No socioeconomic stereotypes

**Contexts:**
- [ ] Culturally inclusive
- [ ] Relevant to diverse experiences
- [ ] No assumptions about backgrounds

**CEID 11 Categories:**
1. Ageism - [ ] Age-appropriate
2. Classism - [ ] Economic diversity
3. Gender Bias - [ ] Gender balance
4. Regional Bias - [ ] No geography assumptions
5. Language Bias - [ ] Respectful of multilingualism
6. Religious Bias - [ ] Inclusive, secular
7. Racial/Ethnic Bias - [ ] Diverse, no stereotypes
8. Sexual Orientation Bias - [ ] Inclusive families
9. Exceptionality Bias - [ ] Positive disability representation
10. Body Type Bias - [ ] Diverse body types
11. Situational Bias - [ ] Diverse life situations

**Reference:** `/universal/content-equity/ceid-guidelines.md`

---

### Section 7: State Compliance

**How to Review:**

1. **Identify the state:**
   - Check content brief or curriculum config file
   - Locate state compliance KB files in `/districts/[state]/compliance/`

2. **For Texas content:**
   - Open `/districts/texas/compliance/sboe-quality-rubric.md`
     - Check Criterion 1: TEKS alignment (comprehensive coverage)
     - Check Criterion 2: Instructional design (gradual release, formative assessment)
     - Check Criterion 3: Assessment quality (aligned, varied types)
     - Check Criterion 4: Support for ELLs (ELPS integration)
     - Check Criterion 5: Support for diverse learners (scaffolds, extensions)
   - Open `/districts/texas/compliance/ipacc-suitability-requirements.md`
     - Content restrictions: Check for prohibited topics/approaches
     - Factual accuracy required
   - Verify ELPS standards are explicitly addressed (cross-check with Section 3: Language Support)

3. **For California content:**
   - Open `/districts/california/compliance/california-adoption-criteria.md`
     - Standards alignment: CCSS/NGSS comprehensive coverage
     - Instructional design: Evidence-based practices
     - Assessment alignment
     - ELD Standards integration (Beginning, Intermediate, Bridging levels)
     - Content suitability for CA context
   - Check for CA-specific sensitivities (environmental awareness, diversity requirements)

4. **For Florida content:**
   - Open `/districts/florida/compliance/florida-adoption-criteria.md`
     - Statutory compliance: F.S. 1006.31-1006.40 (review requirements)
     - B.E.S.T. or MAFS or NGSSS standards alignment
     - ESOL/WIDA supports present (Beginning, Intermediate, Advanced)
   - Check for FL-specific content rules

5. **Document compliance:**
   - For each criterion, note: PASS / FAIL / NEEDS REVISION
   - Reference specific KB file sections
   - Be prepared to explain compliance to stakeholders

**Texas:**
- [ ] SBOE Quality Rubric criteria 1-5
- [ ] IPACC suitability requirements
- [ ] Content restrictions complied with
- [ ] ELPS standards addressed

**California:**
- [ ] Adoption criteria met
- [ ] ELD Standards addressed
- [ ] Content suitable

**Florida:**
- [ ] Statutory compliance (F.S. 1006.31-1006.40)
- [ ] B.E.S.T./MAFS standards addressed
- [ ] ESOL/WIDA supports present

**Reference:**
- `/districts/texas/compliance/sboe-quality-rubric.md`
- `/districts/texas/compliance/ipacc-suitability-requirements.md`
- `/districts/california/compliance/california-adoption-criteria.md`
- `/districts/florida/compliance/florida-adoption-criteria.md`

---

### Section 8: Technical Quality

**How to Review:**

1. **Check writing mechanics:**
   - Use spell-check, but also read carefully (spell-check misses "there/their/they're")
   - Check grammar: Subject-verb agreement, proper tense, clear pronoun references
   - Check punctuation: Commas, periods, apostrophes used correctly
   - Style: Check against HMH style guide for consistency (if available)
   - Academic tone: Age-appropriate but not patronizing

2. **Check formatting consistency:**
   - Headings: Are levels used correctly and consistently?
   - Lists: Are bullets/numbers used correctly? (Parallel structure?)
   - Tables: Are they formatted consistently? Headers clear?
   - Indentation: Is it consistent throughout?
   - White space: Is content scannable or overwhelming?

3. **Check completeness:**
   - Compare against template: Are all required sections present?
   - Search for placeholders: [TBD], [TODO], [INSERT], ???, XXXX
   - Check answer key: Is every problem/question answered?
   - Check metadata: Title, grade, subject, standards, time estimate all filled in?

4. **Verify answer key carefully** (Critical!):
   - **Independently solve every problem yourself**
   - Do NOT just skim - errors in answer keys are common
   - Check that explanation/work shown is correct (not just final answer)
   - For open-ended questions, check that rubric aligns with exemplar responses

5. **Check assets and materials:**
   - Are all referenced images listed or included?
   - Are image descriptions clear enough for designers to create/source?
   - Are materials lists complete? (Manipulatives, handouts, tech requirements)
   - Are file names/references correct?

6. **Professional presentation:**
   - Does this look complete and professional?
   - Is it ready for the next stage (production, translation, design)?

**Writing:**
- [ ] Spelling correct
- [ ] Grammar correct
- [ ] Punctuation correct
- [ ] Style consistent with HMH standards

**Formatting:**
- [ ] Headings used correctly
- [ ] Lists formatted consistently
- [ ] Tables formatted properly
- [ ] Indentation consistent

**Completeness:**
- [ ] All template sections present
- [ ] No "[TBD]" or placeholders
- [ ] Answer key complete
- [ ] Metadata complete

**Assets:**
- [ ] All images specified or included
- [ ] Descriptions clear for designers
- [ ] Materials clearly listed

---

### Section 9: Common Cartridge Compatibility

**When to Review:**
This section applies when content will be packaged as Common Cartridge (.imscc) for LMS delivery (Canvas, Moodle, Blackboard). Check with production to confirm packaging format.

**How to Review:**

1. **Check QTI-compatible assessment structure:**
   - Open `/templates/qti/README.md` to understand QTI item types
   - Verify assessments use supported item types:
     - ✅ Multiple choice, True/False (choiceInteraction)
     - ✅ Fill-in-the-blank, short answer (textEntryInteraction)
     - ✅ Essay questions (extendedTextInteraction)
     - ✅ Matching, ordering (matchInteraction)
     - ✅ Dropdown selections (inlineChoiceInteraction)
     - ❌ Highly interactive custom items may not export cleanly
   - Each assessment item should have:
     - Clear question stem
     - Point value specified
     - Correct answer marked
     - Feedback for correct/incorrect (if applicable)
     - Rationale or explanation

2. **Verify file references are CC-friendly:**
   - Check all asset references (images, videos, PDFs):
     - ✅ Relative paths: `images/diagram1.png` or `./assets/video.mp4`
     - ❌ Absolute paths: `/Users/name/Desktop/image.png` or `C:\Documents\file.pdf`
     - ❌ External URLs requiring authentication
   - File names should be web-safe:
     - ✅ Lowercase, hyphens, no spaces: `cell-diagram-1.png`
     - ❌ Spaces, special characters: `Cell Diagram (Final).png`

3. **Check content structure for CC packaging:**
   - Is content organized into logical modules/units?
   - Each module should have clear sequence (Module 1, Module 2, etc.)
   - Assessment placement is clear (end of module, standalone quiz, etc.)
   - Check for discussion topics: Are prompts clear and point values specified?

4. **Verify LTI tool documentation (if applicable):**
   - If content references external tools/simulations:
     - Is LTI launch URL documented?
     - Are required LTI settings specified? (privacy level, custom parameters)
     - Is tool configuration clear for production team?
   - Reference: `/templates/common-cartridge/v1.3/lti-tool.xml`

5. **Check gradebook requirements:**
   - Are assignment groups specified? (Quizzes, Homework, Projects, etc.)
   - Are point values and weights clear?
   - Is grading type specified for each assessment? (Points, percentage, complete/incomplete, letter grade)

6. **Validate module prerequisites (if applicable):**
   - If content specifies "Module 2 requires Module 1 completion":
     - Prerequisites are clearly documented
     - Prerequisite logic is simple (no complex branching)

7. **Review for CC production handoff:**
   - Open `/PRODUCTION_GUIDE.md` Section 3 (Common Cartridge Format 3B)
   - Ask: "Does production have everything they need?"
     - Module structure document or clear hierarchy
     - Complete assessment files with answer keys
     - All assets referenced are included or clearly specified
     - Discussion topics documented (if any)
     - LTI tools documented (if any)
     - Gradebook configuration specified

**Checklist:**

**QTI Assessment Compatibility:**
- [ ] All item types are QTI-compatible (MC, FIB, essay, matching, dropdown)
- [ ] Point values specified for all items
- [ ] Correct answers clearly marked
- [ ] Feedback/rationales provided where appropriate

**File References:**
- [ ] All file paths are relative (not absolute)
- [ ] File names are web-safe (lowercase, hyphens, no spaces)
- [ ] No external URLs requiring authentication
- [ ] All referenced assets included or specified

**Content Structure:**
- [ ] Logical module/unit organization
- [ ] Clear content sequence
- [ ] Assessment placement documented
- [ ] Discussion topics have prompts and point values

**External Tools (if applicable):**
- [ ] LTI launch URLs documented
- [ ] LTI settings specified (privacy, parameters)
- [ ] Tool configuration clear for production

**Gradebook Configuration:**
- [ ] Assignment groups specified (if needed)
- [ ] Point values and weights clear
- [ ] Grading types specified (points, percentage, etc.)

**Production Handoff:**
- [ ] Module structure/hierarchy documented
- [ ] Complete assessment files with answer keys
- [ ] All assets included or specified
- [ ] Discussion topics documented (if any)
- [ ] LTI tools documented (if any)
- [ ] Gradebook settings specified

**Reference:**
- `/templates/common-cartridge/README.md` - CC packaging overview
- `/templates/common-cartridge/VERSION_SUPPORT.md` - CC/QTI version guidance
- `/templates/qti/README.md` - QTI item types and compatibility
- `/PRODUCTION_GUIDE.md` Section 3 (Format 3B) - CC production workflow
- Skills: `curriculum.package-common-cartridge`, `curriculum.validate-cc`

---

## 4. Providing Effective Feedback

### Principles

**1. Be Specific**
❌ "This section needs work."
✅ "Guided practice needs scaffolding. Add sentence frames for Beginning ELLs and graphic organizer for Intermediate ELLs."

**2. Be Actionable**
❌ "Language support is weak."
✅ "Add ELPS 3.E scaffolds: Beginning needs visual models and frame 'I see ___ because ___.'"

**3. Explain Why**
❌ "Change this problem."
✅ "Change this problem. Context assumes amusement park visit (CEID: classism). Use school playground instead."

**4. Balance Critical and Positive**
Always start with strengths.

**5. Prioritize**
Separate "must fix" from "nice to have."

### Feedback Template: Lessons

```markdown
## Editorial Review: [Lesson Title]

**Reviewer:** [Name]
**Date:** [Date]
**Status:** ❌ Requires Revisions / ⚠️ Minor Changes / ✅ Approved

---

### Strengths
- Strong MLR2 use in guided practice - clear protocol
- Excellent differentiation with graphic organizer
- Formative checks embedded throughout
- Complete answer key

---

### Required Changes (Must Fix)

#### 1. Standards Alignment
**Issue:** Objective 2 doesn't map to TEKS.5.NF.1.1.
**Fix:** Revise to: "Students will add fractions with unlike denominators using visual models."
**Reference:** `/subjects/mathematics/districts/texas/teks-math-alignment.md` line 487

#### 2. ELPS Scaffolding
**Issue:** Missing Beginning level scaffolds in warm-up.
**Fix:** Add frame: "I think ___ because ___." Provide visual model.
**Reference:** ELPS 3.E requires Beginning sentence frames.

#### 3. Accessibility
**Issue:** Figure 2 has no alt text.
**Fix:** Add: "Two fraction bars showing 1/3 shaded blue and 1/4 shaded red with twelfths grid."
**Reference:** WCAG 2.1 SC 1.1.1

---

### Suggested Changes (Optional)

#### 1. UDL Enhancement
**Suggestion:** In independent practice, offer choice: visual models, number lines, OR algorithms. Currently only algorithm.
**Benefit:** Multiple means of action/expression.

#### 2. Misconception Addressing
**Suggestion:** Add teacher note about "adding across" error. Ask "Does 1/2 + 1/3 = 2/5?" to surface misconception.
**Benefit:** Proactively addresses predictable error.

---

### Questions
1. Exit ticket mentioned (line 287) - provided separately or included?
2. Warm-up references "yesterday's lesson" - correct sequencing?

---

### Next Steps
Address 3 required changes and answer questions. Suggested changes optional but recommended. Tag me when revised.

Time estimate: 30-45 min

Great work on instructional routines!
```

### Feedback Template: Assessments

```markdown
## Editorial Review: [Assessment Title]

**Status:** ❌ Requires Revisions / ✅ Approved

---

### Strengths
- Blueprint alignment excellent
- Rubrics detailed and clear
- Distractors address real misconceptions

---

### Required Changes

#### Item 7
**Issue:** Distractor C not plausible.
**Fix:** Change to "1 1/7 yards" (common error).
**Rationale:** Addresses treating fractions like whole numbers.

#### Item 12
**Issue:** Assumes students have pets (CEID: situational bias).
**Fix:** Use school supplies or classroom materials.

#### Item 18
**Issue:** Rubric doesn't specify scoring if correct answer without work.
**Fix:** Add: "Correct answer without explanation: maximum 2 points."

---

### Accessibility

#### Item 3
**Issue:** Graph has no alt text.
**Fix:** Add: "Bar graph showing Amy 85, Juan 90, Chen 78."

#### Item 15
**Issue:** Color-coded choices (green/red) convey information.
**Fix:** Add text labels OR remove color.

---

Great rubrics - very clear for scoring!
```

### Common Scenarios

**Scenario 1: Missing KB Application**

**Feedback:**
"MLR1 in guided practice is missing Round 3. Per `/subjects/mathematics/common/mlr/mlr1-stronger-clearer.md`, MLR1 requires:
1. Individual think
2. Partner A shares, B responds
3. **Partners switch and refine**

Please add Round 3 for students to refine explanations."

**Scenario 2: Standards Misalignment**

**Feedback:**
"This lesson addresses TEKS.5.NF.1.1 but practice uses only denominators 2, 3, 6 (all factor to 6).

Per `/subjects/mathematics/districts/texas/teks-math-alignment.md` (line 492), 5th grade includes denominators requiring LCM like 4 and 6 (LCM 12) or 3 and 5 (LCM 15).

Revise 30% of problems to include complex denominators."

**Scenario 3: Accessibility Gap**

**Feedback:**
"Figure 3 color codes answers (green = correct, red = incorrect). This creates barrier for colorblind users (8% of males).

Per `/universal/accessibility/wcag-compliance-guide.md` (WCAG 1.4.1), information cannot be by color alone.

**Fix:** Add text labels: ✓ Correct and ✗ Incorrect OR use shape + color."

**Scenario 4: Missing ELL Scaffolds**

**Feedback:**
"Lesson addresses ELPS 4.G but no scaffolds for Beginning/Intermediate ELLs during read-aloud (lines 145-178).

Per `/districts/texas/language/elps-alignment.md`:
- **Beginning:** Provide visual cards, allow pointing/single words
- **Intermediate:** Frame: 'The character feels ___ because ___.'"

---

## 5. Approval Process

### When to Approve

**Ready for approval when:**
- [ ] All required changes addressed
- [ ] Meets all 7 quality pillars
- [ ] Author responded to questions
- [ ] No outstanding concerns

**"Almost there":**
- Use **"Approved with Minor Changes"**
- List minor changes
- Trust author to make them
- No re-review needed

**Fundamental issues:**
- Do NOT approve
- Provide clear feedback
- Set expectations

### Approval Steps

**Step 1: Final Review**
- Re-read with fresh eyes
- Verify all changes made
- Check for new issues

**Step 2: Approval Comment**
```markdown
## ✅ APPROVED

Meets all quality standards. Ready for publication.

### Revisions Completed
- Added ELPS scaffolds ✓
- Revised Learning Objective 2 ✓
- Added alt text to images ✓
- Addressed misconception ✓

### Final Notes
- Excellent MLR2 use - model for others
- Strong differentiation
- Clear teacher notes

Merging to /published/. Great work!
```

**Step 3: Merge PR**
- Click "Approve"
- Merge pull request
- Content moves to `/published/`
- Notify author

**Step 4: Document (if applicable)**
- Note exemplary features for training
- Document creative solutions

---

## 6. Common Issues and Fixes

### Issue 1: Weak Learning Objectives

**Problem:**
❌ "Students will understand fractions."

**Fix:**
✅ "Students will compare fractions with unlike denominators using visual models and explain their reasoning."

Use Bloom's Taxonomy action verbs.

**Reference:** `/universal/frameworks/dok-framework.md`

---

### Issue 2: Missing Misconceptions

**Problem:** Doesn't anticipate errors.

**Fix:** For fractions, "adding across" (1/2 + 1/3 = 2/5) is most common.

Add note: "Watch for adding across. Ask: 'Does 1/2 + 1/3 = 2/5? Test with pizza.' Cognitive conflict helps."

---

### Issue 3: Generic Sentence Frames

**Problem:**
❌ "I think ___."

**Fix:**
✅ "To find the common denominator, I need to ___."
✅ "I know my answer is reasonable because ___."

Make frames task-specific.

**Reference:** `/universal/frameworks/sentence-frames-library.md`

---

### Issue 4: Poor Alt Text

**Problem:**
❌ "Image of fractions"

**Fix:**
✅ "Two fraction bars aligned vertically. Top shows 2/3 shaded blue. Bottom shows 3/4 shaded red. Both have twelfths grid."

Describe content and function.

**Reference:** `/universal/accessibility/wcag-compliance-guide.md`

---

### Issue 5: Token Diversity

**Problem:** Limited diversity - all English names, affluent contexts.

**Fix:**
- Use diverse names (African, Asian, Latinx, European)
- Vary contexts: public parks not country clubs, public library not home office

**Reference:** `/universal/content-equity/ceid-guidelines.md`

---

### Issue 6: Incorrect Routine

**Problem:** Says MLR1 but protocol doesn't match.

**Fix:** Consult MLR file. **MLR1 requires:**
1. Individual think
2. Partner A shares (1 min)
3. Partner B responds (30 sec)
4. Switch roles
5. Individual revision

If missing steps, revise OR choose different routine.

**Reference:** `/subjects/mathematics/common/mlr/mlr1-stronger-clearer.md`

---

### Issue 7: Answer Key Errors

**Problem:** Incorrect answer or incomplete solution.

**Fix:**
- Solve every problem yourself
- Check author's key
- Provide correct solution with explanation

**Critical:** Never approve with answer key errors. Undermines teacher trust.

---

## 7. Complete Review Examples

This section shows two complete editorial reviews with annotations explaining editorial decisions.

---

### Example 1: Strong Lesson - Approved with Minor Changes

**Content Type:** Grade 5 Texas Math Lesson - Adding Fractions with Unlike Denominators
**Author:** Experienced (3rd lesson)
**Review Time:** 1.5 hours
**Outcome:** ✅ Approved with Minor Changes

#### The Lesson (Excerpted)

```markdown
# Adding Fractions with Unlike Denominators
**Grade:** 5 | **Subject:** Mathematics | **Duration:** 60 minutes
**Standards:** TEKS.5.3.K, ELPS.3.E
**Learning Objectives:**
- Students will add fractions with unlike denominators using visual models
- Students will explain their addition strategy using mathematical language

## Lesson Sequence

### Warm-Up (10 minutes) - MLR8: Discussion Supports

**Prompt:** "Which is greater: 1/2 + 1/4 OR 1/3 + 1/6? Use models to explain."

**Think-Pair-Share:**
- Think: 2 min (provide fraction strips)
- Pair: 3 min (discuss with partner)
- Share: 5 min (whole class)

**MLR8 Supports:**
- Display frame: "I think ___ is greater because ___."
- Revoice student explanations
- Press for details: "Can you show that with your model?"

**Scaffolds for Emergent Bilinguals:**
- Beginning: Visual fraction strips required, frame: "___ is greater."
- Intermediate: Frame: "I used ___ to find that ___."
- Advanced: Encourage: "I can prove this by..."

**Formative Check:** 80% can identify which is greater with model

---

### Instruction (20 minutes) - Teacher Models

**I Do:** Teacher demonstrates adding 2/3 + 1/4

[Teacher think-aloud provided with visual]

**We Do:** Class adds 3/5 + 1/10 together

[Guided practice steps provided]

**Common Misconception:**
"Adding across" (2/3 + 1/4 = 3/7)
Address: "Let's test 2/3 + 1/4 = 3/7 with pizza slices. Does it work?"

---

[Rest of lesson continues...]

## Answer Key
[Complete solutions provided]

## Assets Needed
- Image 1: Fraction strips - 1200x800px
  Alt text: "Fraction strips showing thirds and fourths aligned"
- Image 2: Number line 0 to 1 with common denominators marked
  Alt text: "Number line from 0 to 1 showing twelfths"
```

---

#### Editorial Review with Annotations

**EDITOR COMMENT - Line 3 (Standards):**
```
✅ GOOD: Standards from brief addressed (TEKS.5.3.K, ELPS.3.E)
```
**Editor thinking:** Standards listed. Now I need to verify these are correct. Let me check KB file...

**EDITOR ACTION:**
- Opens `/subjects/mathematics/districts/texas/teks-math-alignment.md`
- Finds TEKS.5.3.K: "Add and subtract fractions with unlike denominators"
- Confirms this lesson matches standard intent ✓

---

**EDITOR COMMENT - Line 5-6 (Objectives):**
```
✅ STRONG: Measurable objectives using Bloom's verbs ("add," "explain")
✅ Both objectives map directly to TEKS.5.3.K
```
**Editor thinking:** "Add" and "explain" are measurable. Direct alignment to standard. Good.

---

**EDITOR COMMENT - Line 11-18 (MLR8):**
```
✅ EXCELLENT: MLR8 protocol correctly applied per KB file
✓ Discussion supports explicitly taught
✓ Think-Pair-Share structure clear
✓ Sentence frames provided

REFERENCE CHECK: Opened /subjects/mathematics/common/mlr/mlr8-discussion-supports.md
- Confirms protocol matches ✓
```
**Editor thinking:** Let me verify against MLR8 KB file... Yes, this matches the protocol. Discussion supports are explicit, not just mentioned. Strong.

---

**EDITOR COMMENT - Line 20-24 (EB Scaffolds):**
```
✅ STRONG: Three-tiered EB scaffolds specific and actionable
✓ Beginning: Visual + simplified frame
✓ Intermediate: Sentence starter appropriate
✓ Advanced: Encouragement to elaborate

⚠️ MINOR: ELPS 3.E requires explicit mention. Add note referencing ELPS.
```
**Editor thinking:** Scaffolds are specific (not generic). Three levels present. But ELPS standard should be explicitly referenced in this section. Minor fix needed.

---

**EDITOR COMMENT - Line 26 (Formative Check):**
```
✅ GOOD: Specific success criterion (80% threshold)
```
**Editor thinking:** Clear formative check with measurable criterion. Good practice.

---

**EDITOR COMMENT - Line 38-41 (Misconception):**
```
✅ EXCELLENT: Anticipates most common error
✓ Uses cognitive conflict strategy (pizza test)
✓ Addresses proactively

This is exemplary misconception addressing.
```
**Editor thinking:** This is exactly what we want. Common error predicted, specific strategy to address. This section could be used as a model for other authors.

---

**EDITOR COMMENT - Line 58 (Answer Key):**
```
❌ REQUIRED: Checked problems 3, 5, 7
Problem 7: Answer key shows 11/12 but correct answer is 13/12 = 1 1/12

MUST FIX: Verify and correct answer key for problem 7
```
**Editor thinking:** Always verify answer keys. Let me solve problem 7 myself... 2/3 + 3/4 = 8/12 + 9/12 = 17/12 = 1 5/12. Author has wrong answer. Critical error - must fix.

---

**EDITOR COMMENT - Line 62-65 (Alt Text):**
```
✅ EXCELLENT: Alt text descriptive and functional
✓ Describes content ("showing thirds and fourths")
✓ Describes arrangement ("aligned")

WCAG 2.1 SC 1.1.1 compliant ✓
```
**Editor thinking:** Alt text meets WCAG standards. Specific enough for screen reader users to understand the image. Perfect.

---

#### Final Review Comment

```markdown
## ✅ APPROVED WITH MINOR CHANGES

**Overall:** Strong lesson. Excellent MLR8 application, specific EB scaffolds, good misconception addressing. One answer key error (critical) and one minor ELPS reference needed.

---

### Strengths
- MLR8 protocol correctly applied - could be model for others
- EB scaffolds specific and actionable at all 3 levels
- Proactive misconception addressing with cognitive conflict strategy
- Clear formative checks throughout
- Excellent alt text (WCAG compliant)

---

### Required Changes (MUST FIX)

#### 1. Answer Key Error (Line 58, Problem 7) - CRITICAL
**Issue:** Answer key shows 11/12 but correct answer is 1 5/12
**Fix:**
2/3 + 3/4 = 8/12 + 9/12 = 17/12 = 1 5/12
Correct answer key problem 7 to show 1 5/12 with full work

**Why:** Answer key errors undermine teacher trust. Always critical.

---

### Suggested Changes (RECOMMENDED)

#### 1. ELPS Reference (Line 20-24)
**Suggestion:** Add note: "Per ELPS 3.E: Support students in sharing information in cooperative learning"
**Why:** Makes explicit connection to standard for teacher awareness

---

### What I Verified

✅ Standards alignment: Checked against `/subjects/mathematics/districts/texas/teks-math-alignment.md`
✅ MLR8 protocol: Verified against `/subjects/mathematics/common/mlr/mlr8-discussion-supports.md`
✅ ELPS standards: Checked against `/districts/texas/language/elps-alignment.md`
✅ Answer key: Solved all problems independently
✅ Alt text: Verified WCAG 2.1 SC 1.1.1 compliance

---

### Next Steps
Fix answer key error (critical), add ELPS note (recommended). Time estimate: 10 minutes.

Once fixed, will approve and merge immediately. Excellent work - particularly strong on MLR application.

---

**Estimated Revision Time:** 10 minutes
**Re-Review Needed:** Quick check only (answer key verification)
```

#### What This Review Demonstrates

**Editor Skills Shown:**
1. **Verification against KB files** - Didn't just check boxes, actually opened files
2. **Independent problem solving** - Solved all answer key problems
3. **Specific feedback** - Exact line references, exact corrections
4. **Balanced feedback** - Started with strengths, clear priorities
5. **Actionable** - Author knows exactly what to fix
6. **Professional tone** - Encouraging while maintaining standards

**Decision-Making:**
- Recognized strong work (MLR8, scaffolds, misconceptions)
- Caught critical error (answer key)
- Prioritized: Critical fix vs recommended enhancement
- Used "Approved with Minor Changes" appropriately (one critical fix, otherwise excellent)

**Time Management:**
- 1.5 hours for thorough review
- Balanced: Not too fast (missed errors) or too slow (over-analyzing)

---

### Example 2: Needs Major Revision - Requires Multiple Changes

**Content Type:** Grade 3 California ELA Lesson - Character Analysis
**Author:** New (1st lesson)
**Review Time:** 2 hours
**Outcome:** ❌ Requires Revisions

#### The Lesson (Excerpted with Issues)

```markdown
# Understanding Characters
**Grade:** 3 | **Subject:** ELA | **Duration:** 45 minutes
**Standards:** CCSS.ELA-LITERACY.RL.3.3
**Learning Objectives:**
- Students will understand characters

## Lesson

### Warm-up
Students think about their favorite character from a book.

### Reading
Teacher reads "The Three Little Pigs." Students listen.

### Discussion
Ask students: "What did you notice about the characters?"

Students share their thoughts.

### Activity
Students draw their favorite character and write why they like them.

**For ELL students:** Provide support as needed.

### Closing
Review what we learned about characters.

## Answer Key
N/A (no assessment)
```

---

#### Editorial Review with Annotations

**EDITOR COMMENT - Line 1 (Title):**
```
⚠️ VAGUE: "Understanding Characters" too general
SUGGESTION: "Analyzing Character Traits in Folk Tales" (more specific)
```

---

**EDITOR COMMENT - Line 3 (Standards):**
```
❌ REQUIRED: Incomplete standards list
**Issue:** Missing CA ELD standards (required for California)
**Fix:** Add ELD.PI.3.1 (exchanging information) or appropriate ELD standard

REFERENCE: /districts/california/language/eld-alignment.md requires ELD standards for all lessons
```
**Editor thinking:** California requires ELD standards. None listed. This is non-negotiable for CA adoption.

---

**EDITOR COMMENT - Line 4-5 (Learning Objective):**
```
❌ REQUIRED: Not measurable
**Problem:** "Understand" is not a measurable verb (Bloom's Taxonomy)
**Fix:**
- "Students will identify three character traits using text evidence"
- "Students will describe character motivations using specific details from the text"

REFERENCE: /universal/frameworks/dok-framework.md - Use action verbs: identify, describe, explain, analyze
```
**Editor thinking:** "Understand" is classic weak objective. Not measurable. Author needs specific, measurable objectives with Bloom's verbs.

---

**EDITOR COMMENT - Line 9-10 (Warm-up):**
```
❌ REQUIRED: No structure, no EB scaffolds, no formative check
**Missing:**
- Think-Pair-Share or Turn-and-Talk structure
- EB scaffolds for Beginning/Intermediate/Advanced
- Sentence frames
- Formative check

**Fix:** Apply literacy routine (Think-Pair-Share or Turn-and-Talk) with full protocol

REFERENCE: /subjects/ela/common/literacy-routines/think-pair-share.md
```
**Editor thinking:** This is too vague. "Students think" - for how long? What structure? No scaffolds for ELLs. Needs complete revision with actual protocol.

---

**EDITOR COMMENT - Line 12-13 (Reading):**
```
❌ REQUIRED: Not a CA ELD standards-aligned lesson on character analysis
**Issue:** "Students listen" is passive, no interaction
**Missing:**
- Close Reading Protocol for text analysis
- Annotation strategies
- Text-dependent questions
- Multiple reads with different purposes

**Fix:** Apply Close Reading Protocol with 3 reads:
1. Read for gist
2. Read for character actions/words
3. Read for traits/motivations

REFERENCE: /subjects/ela/common/literacy-routines/close-reading-protocol.md
```
**Editor thinking:** This doesn't teach character analysis at all. Students just listen? For character analysis, need Close Reading Protocol with focused attention on character details. Major gap.

---

**EDITOR COMMENT - Line 15-18 (Discussion):**
```
❌ REQUIRED: No protocol, generic question, no scaffolds
**Problems:**
- Question too broad ("what did you notice")
- No discussion protocol
- No sentence frames
- No strategy for ensuring participation

**Fix:**
- Use Turn-and-Talk or Think-Pair-Share
- Specific question: "What words describe the first pig? Find evidence in text."
- Add sentence frames:
  - Beginning: "The pig is ___." (provide word bank: hardworking, lazy, clever)
  - Intermediate: "I think the pig is ___ because ___."
  - Advanced: "The author shows the pig is ___ when ___."

REFERENCE: /districts/california/language/eld-alignment.md (ELD proficiency levels)
```
**Editor thinking:** Generic "share your thoughts" doesn't teach anything. Need structured protocol with text-dependent questions and tiered scaffolds.

---

**EDITOR COMMENT - Line 20-21 (Activity):**
```
❌ REQUIRED: Multiple issues

**CEID Concern - Situational Bias:**
"Draw their favorite character" assumes:
- All students have favorite books/characters (access to books)
- All students comfortable drawing (ability bias)

**Fix:** Use the shared text (Three Little Pigs) instead:
"Draw one pig and label with 3 character traits from the story"

REFERENCE: /universal/content-equity/ceid-guidelines.md Category 11 (Situational Bias)

**UDL Concern:**
Only one means of expression (draw + write). Need options.

**Fix:** "Choose one way to show character traits:
- Draw and label
- Write 3-4 sentences
- Create character trait web"

REFERENCE: /universal/frameworks/udl-principles-guide.md (Multiple Means of Action/Expression)
```
**Editor thinking:** Multiple problems here. Assumes all students have books at home (classism). Only one way to respond (not UDL). Both need fixing.

---

**EDITOR COMMENT - Line 23 (ELL Support):**
```
❌ REQUIRED: Completely insufficient
**Problem:** "Provide support as needed" is not scaffolding

CA requires specific ELD scaffolds for Beginning, Intermediate, Bridging levels.

**Must include:**
- Beginning: Visual supports, word banks, sentence frames, reduced output
- Intermediate: Sentence frames, visual supports, vocabulary support
- Bridging: Academic language frames, vocabulary extensions

**Fix:** See /districts/california/language/eld-alignment.md for examples and requirements

This is non-negotiable for CA adoption.
```
**Editor thinking:** This violates CA ELD requirements. "Support as needed" means nothing to a teacher. Specific scaffolds required by state. Major compliance issue.

---

**EDITOR COMMENT - Line 25-26 (Closing):**
```
⚠️ WEAK: No formative assessment
**Missing:** Exit ticket or check for understanding
**Suggestion:** Add exit ticket:
"Write one character trait for the first pig. What makes you think that? Use evidence from story."

Allows teacher to check if objective met.
```

---

**EDITOR COMMENT - Line 28-29 (Answer Key):**
```
❌ REQUIRED: N/A is not acceptable
**Issue:** Even without formal assessment, need exemplar responses

**Fix:** Provide:
- Sample character traits for each pig with text evidence
- Exemplar student response for activity
- Rubric or success criteria

Teachers need this for guidance.
```

---

**EDITOR COMMENT - Missing Throughout:**
```
❌ REQUIRED: Missing sections
- No materials list
- No preparation notes
- No timing for each section
- No images/assets specified
- No alt text for any visuals
- No differentiation section
- No misconceptions addressed
```

---

#### Final Review Comment

```markdown
## ❌ REQUIRES MAJOR REVISIONS

**Overall:** This draft needs significant development before approval. The structure is too generic, missing required CA ELD standards and scaffolds, and lacks pedagogical depth for character analysis instruction.

**Assessment:** This reads more like a brief outline than a complete lesson. It needs to be developed into a full instructional sequence.

---

### Critical Issues (MUST FIX - Non-Negotiable)

#### 1. Standards - INCOMPLETE
**Problem:** Missing CA ELD standards (required)
**Fix:** Add appropriate ELD standard (suggest ELD.PI.3.1)
**Reference:** `/districts/california/language/eld-alignment.md`

#### 2. Learning Objective - NOT MEASURABLE
**Problem:** "Understand" is not measurable
**Fix:** Use Bloom's verbs: "Students will **identify** three character traits using text evidence"
**Reference:** `/universal/frameworks/dok-framework.md`

#### 3. ELL Scaffolds - INSUFFICIENT
**Problem:** "Support as needed" does not meet CA ELD requirements
**Fix:** Add specific scaffolds for Beginning/Intermediate/Bridging levels in EVERY section
**Example:** Beginning needs word banks, sentence frames, visual supports
**Reference:** `/districts/california/language/eld-alignment.md` lines 145-230

#### 4. Instructional Routines - MISSING
**Problem:** No literacy routines applied
**Fix:**
- Warm-up: Apply Think-Pair-Share or Turn-and-Talk (full protocol)
- Reading: Apply Close Reading Protocol (3 reads for character analysis)
- Discussion: Structured protocol with specific questions

**References:**
- `/subjects/ela/common/literacy-routines/close-reading-protocol.md`
- `/subjects/ela/common/literacy-routines/think-pair-share.md`

#### 5. CEID Violation - Situational Bias
**Problem:** "Draw your favorite character" assumes book access
**Fix:** Use shared classroom text: "Draw one pig from Three Little Pigs with traits"
**Reference:** `/universal/content-equity/ceid-guidelines.md` Category 11

#### 6. UDL - No Options
**Problem:** Only one means of expression (draw + write)
**Fix:** Offer 2-3 options: draw, write, or graphic organizer
**Reference:** `/universal/frameworks/udl-principles-guide.md`

#### 7. Answer Key - Missing
**Problem:** "N/A" not acceptable
**Fix:** Provide exemplar responses and success criteria

---

### Structure and Completeness Issues

#### Missing Sections:
- Materials list (what teacher/students need)
- Preparation notes
- Timing for each section (critical for 45-min lesson)
- Differentiation section (by readiness level)
- Common misconceptions
- Complete answer key/exemplars
- Assets list with alt text

#### Generic Language:
Current lesson uses vague phrases like:
- "Students think about..."
- "Students share their thoughts..."
- "Review what we learned..."

**Fix:** Be specific with protocols, timing, questions, scaffolds

---

### What Needs to Happen

This lesson needs substantial development. I recommend:

1. **Study approved examples** (Section 7, Example 1)
2. **Read KB files thoroughly:**
   - Close Reading Protocol
   - CA ELD alignment
   - Think-Pair-Share
   - UDL principles
   - CEID guidelines

3. **Use AUTHOR_GUIDE.md Section 4 lesson template**
   - It has all required sections
   - Follow the structure exactly
   - Don't skip any sections

4. **Review CA ELA Grade 3 example** in AUTHOR_GUIDE.md Section 3.6
   - Shows Close Reading Protocol in action
   - Shows ELD scaffolds
   - Complete example to follow

---

### Estimated Revision Time

**3-5 hours of significant work needed**

This is typical for a first lesson. Don't be discouraged - everyone's first lesson needs major revision. The learning curve is steep initially but you'll improve rapidly.

---

### Recommended Approach

**Option 1 (Recommended):** Schedule 30-minute call to review feedback together
- I can walk you through what's needed
- Faster than multiple revision cycles
- You'll learn more efficiently

**Option 2:** Revise based on feedback and resubmit
- Use AUTHOR_GUIDE.md Section 4 template
- Study approved example (Section 7, Example 1)
- Compare your revision to approved examples line-by-line

Tag me with questions anytime. I'm here to help you succeed!
```

#### What This Review Demonstrates

**Editor Skills Shown:**
1. **Thorough analysis** - Identified multiple categories of issues
2. **References provided** - Every required change cites KB file
3. **Prioritization** - Critical issues separated from structural issues
4. **Educational approach** - Explains what's needed and why
5. **Supportive tone** - Firm on standards but encouraging to new author
6. **Resources provided** - Points to specific guides and examples

**Decision-Making:**
- Recognized this is a first-time author (different approach than experienced author)
- Identified fundamental gaps (not just minor fixes)
- Chose "Requires Major Revisions" (not "Approved with changes")
- Offered synchronous support option (call) for complex feedback
- Normalized struggle ("everyone's first lesson needs major revision")

**Difficult Conversation Handled:**
- Honest assessment: "needs significant development"
- Not sugar-coated, but not harsh
- Specific about what's missing
- Provided clear path forward
- Maintained encouraging tone

**Compliance Issues:**
- Caught CA ELD requirement violation
- Caught CEID bias issue
- Referenced state-specific requirements
- Made clear these are non-negotiable

---

### Key Differences Between Examples

| Aspect | Example 1 (Strong) | Example 2 (Needs Work) |
|--------|-------------------|----------------------|
| **Review Time** | 1.5 hours | 2 hours |
| **Issues Found** | 1 critical, 1 minor | 7 critical, multiple structural |
| **Outcome** | Approved with minor changes | Requires major revisions |
| **Feedback Tone** | Positive, specific fixes | Educational, supportive but firm |
| **Revisions Needed** | 10 minutes | 3-5 hours |
| **Re-Review** | Quick check | Full re-review needed |
| **Author Experience** | Experienced | New (1st lesson) |

---

### What You Learn from These Examples

**From Example 1 (Strong Lesson):**
- What "good enough" looks like
- Even strong lessons may have errors (answer key)
- How to write encouraging feedback
- When to use "Approved with Minor Changes"
- Importance of verifying against KB files

**From Example 2 (Needs Work):**
- How to handle fundamentally weak content
- How to be firm but supportive
- How to prioritize many issues
- When to offer synchronous support
- How to provide educational feedback

**General Lessons:**
- Always verify against KB files (don't just check boxes)
- Be specific with line numbers and exact fixes
- Balance critical and positive feedback
- Provide resources and references
- Adjust tone to author experience level
- Know when to approve vs require revision

---

## 8. Difficult Conversations and Author Management

### Understanding the Author-Editor Dynamic

**Core Principle:** You're on the same team, working toward the same goal (high-quality content).

**Power Dynamic Considerations:**
- You have approval authority (power imbalance exists)
- Authors may feel criticized or defensive
- Your feedback impacts their work and potentially their evaluation
- Building trust is essential for productive collaboration

**Professional Boundaries:**
- Be friendly, but maintain professional standards
- Don't soften required changes to preserve relationship
- Don't let personal feelings (like/dislike) affect review standards
- Separate person from work (critique content, not author)

---

### Common Difficult Conversation Scenarios

#### Scenario 1: Author Pushes Back on Required Changes

**Situation:** Author responds: "I don't think this change is necessary. My approach is valid."

**When Author May Be Right:**
- KB guidance is genuinely ambiguous
- Multiple valid interpretations exist
- Author has research supporting alternative approach
- Issue is truly minor/stylistic

**When You Must Hold Firm:**
- State adoption criteria requirement
- WCAG 2.1 compliance issue
- Standards misalignment
- Missing required scaffold for ELL students

**Response Template:**
```markdown
I understand your perspective. Let me clarify why this is required:

**Requirement:** [State the specific requirement]
**Source:** [KB file reference or adoption criteria]
**Why it matters:** [Explain impact - not just "because I said so"]

**Your approach:** [Acknowledge their idea]
**Issue:** [Specific problem with approach]
**Alternative:** [If flexibility exists, offer options]

This is [non-negotiable / open to discussion if you can show how your approach meets X requirement].

Happy to discuss synchronously if helpful.
```

**When to Escalate:**
- Author refuses non-negotiable requirement after explanation
- Author becomes hostile or unprofessional
- You're genuinely unsure if requirement is negotiable

---

#### Scenario 2: Delivering "This Needs Major Revision" Feedback

**Situation:** Content is fundamentally weak, needs 3-5+ hours of work.

**Author Feelings You're Managing:**
- Disappointment (they thought it was done)
- Frustration (significant time investment ahead)
- Potential embarrassment (especially if new)
- Possible discouragement

**Feedback Structure:**
1. **Start with Context:** "I know you put significant work into this. My role is to ensure it meets state adoption criteria before moving forward."

2. **Be Direct but Kind:** "This draft needs substantial development before approval. This is common for [first lessons / complex topics / new content types]."

3. **Specific Issues:** List critical issues with KB references

4. **Path Forward:** Provide clear next steps

5. **Support Offer:** "I'm happy to do a 30-min call to walk through the main issues" or "Would you like to revise X and Y first, then I can review before you tackle the rest?"

6. **Normalize:** "Your first [lesson/assessment] typically needs major revision. The learning curve is steep initially, but you'll improve rapidly."

**Example Response:**
```markdown
## Status: Requires Major Revisions

I appreciate the work you've put into this draft. After reviewing against Texas adoption criteria and KB standards, this needs substantial development before it's ready for approval.

**This is typical for first lessons** - everyone's first submission needs significant work. The good news is you'll learn a lot from this revision and subsequent lessons will get much easier.

### Critical Issues (Must Address)

[List 3-5 critical issues with KB references and specific fixes]

### Recommended Approach

**Option 1 (Recommended):** Let's schedule a 30-minute call to review feedback together. I can walk you through what's needed, answer questions, and help you create a revision plan. This is usually faster than multiple revision cycles.

**Option 2:** Use the AUTHOR_GUIDE.md Section 4 template and KB files to revise. Compare your revision to approved Example 1 in this guide (Section 7) before resubmitting.

### Resources to Help You

- AUTHOR_GUIDE.md Section 4 (Lesson Authoring Workflow)
- Section 7 Example 1 (Approved strong lesson to model)
- [Specific KB files for your lesson topic]

I'm here to support your success. Tag me with questions anytime.
```

---

#### Scenario 3: Author Is Experienced But Produces Weak Content

**Situation:** Senior author submits content below standards.

**Possible Reasons:**
- Rushed / time pressure
- Unfamiliar with new standards or KB system
- Overconfidence (didn't check KB)
- Personal or professional issues affecting work

**Key Principle:** Same standards apply regardless of seniority.

**Tone Adjustment:** More collegial, less instructional

**Response Template:**
```markdown
Hi [Name],

I've reviewed [content] and have some concerns about alignment to [state] requirements. Can we walk through a few issues?

### Issues Identified

**[Issue 1]:** [Specific problem]
**KB Reference:** [File]
**Fix Needed:** [Specific change]

**[Issue 2]:** [Specific problem]
**KB Reference:** [File]
**Fix Needed:** [Specific change]

I know you're experienced with [subject], so I'm wondering if there's context I'm missing or if these are oversights from timeline pressure?

Let me know if you'd like to discuss - happy to hop on a quick call.
```

**If Pattern Continues:**
- Document pattern
- Discuss with supervisor privately
- May indicate need for training on new systems/standards
- Don't lower standards, but explore root cause

---

#### Scenario 4: You Made a Mistake, Author Catches It

**Situation:** Author responds: "Actually, the KB file says [X], not [Y]. Can you clarify?"

**Your Response:**
1. **Verify immediately:** Check the KB file
2. **If author is right:** Acknowledge quickly

**Response Template:**
```markdown
You're absolutely right - I misread that section of the KB file. Apologies for the confusion.

Your content is correct as written on this point. Please disregard my previous comment about [X].

[Approved / Still need to address [other issues]]
```

**What This Does:**
- Builds trust (you admit mistakes)
- Models professional behavior
- Shows you value accuracy over ego
- Makes future feedback more credible

**What NOT to Do:**
- Defend incorrect feedback
- Move goalposts ("Well, it should say...")
- Over-apologize (brief acknowledgment sufficient)

---

#### Scenario 5: Multiple Editors, Conflicting Feedback

**Situation:** Author says: "Editor A approved this structure, but now you're asking me to change it."

**Diagnosis:**
- May indicate lack of calibration across team
- May indicate legitimate difference in interpretation
- May indicate author misunderstanding previous feedback

**Response:**
```markdown
Thanks for flagging this. Let me look at [Editor A]'s feedback.

[After checking previous review]

**If you're requiring something different:**
"I see Editor A focused on [X], and I'm focusing on [Y]. Both are required for approval. Editor A may have been waiting for [Y] to be addressed in this revision cycle. Let's make sure both are resolved."

**If you're contradicting:**
"You're right that this creates confusion. Let me check with [Editor A] about the interpretation of [requirement]. I'll get back to you within [timeframe] with clarification."

Then: Coordinate with other editor, document decision, inform author.

Apologies for the inconsistency - we'll make sure our team is aligned on this.
```

**System Fix:** Request calibration session with editorial team.

---

### Strategies for Maintaining Professional Relationships

#### 1. Lead with Strengths

**Every review should start with genuine positives:**
- "Strong application of MLR2 protocol"
- "Excellent differentiation with specific scaffolds"
- "Complete, accurate answer key"
- "Thoughtful misconception anticipation"

**Why it matters:**
- Softens critical feedback
- Shows you notice good work
- Motivates improvement
- Builds trust

**Red Flag:** If you genuinely can't find anything positive, content likely needs major revision.

---

#### 2. Explain the "Why"

**Don't just say what's wrong - explain impact:**

❌ "Add ELPS scaffolds"
✅ "Add ELPS scaffolds. Texas adoption requires Beginning/Intermediate/Advanced level support. Without this, content cannot be approved for TX market and teachers won't have guidance for supporting emergent bilinguals."

**Framework:**
- What's wrong
- Why it matters (impact on students, teachers, adoption)
- How to fix
- Where to find guidance

---

#### 3. Offer Choices When Possible

**When multiple valid approaches exist:**

"You need to address UDL principle of multiple means of expression. Three options:
1. Allow students to choose: write, draw, or record response
2. Provide graphic organizer as alternative to paragraph
3. Offer choice of assessment format

Choose the approach that best fits your lesson design."

**Why it works:**
- Respects author's expertise
- Maintains their ownership
- Reduces defensiveness
- Achieves same quality goal

---

#### 4. Calibrate Response to Author Experience

**New Authors:**
- More instructional tone
- Point to specific resources/examples
- Normalize struggle ("everyone's first lesson needs revision")
- Offer synchronous support
- Step-by-step guidance

**Experienced Authors:**
- More collegial tone
- Assume understanding, just remind
- Brief references to KB files
- Focus on specific issues, less hand-holding

**Example - Same Issue, Different Tones:**

**New Author:**
"The learning objective uses 'understand,' which isn't measurable. Learning objectives need action verbs from Bloom's Taxonomy so we can assess if students met the objective.

Try: 'Students will **identify** three character traits' instead of 'Students will understand character traits.'

See AUTHOR_GUIDE.md Section 6.1 for list of measurable verbs and more examples."

**Experienced Author:**
"Line 12: Objective verb should be measurable (Bloom's Taxonomy). Suggest: 'identify' vs 'understand.'"

---

#### 5. Set Clear Expectations

**For Revision Timeline:**
"Please address required changes and resubmit by [date]. If you need more time, let me know by [earlier date] so we can adjust the timeline."

**For Re-Review:**
"Once you've made revisions, tag me and I'll re-review within 2 business days."

**For What's Required vs Suggested:**
Use clear headers:
- **Required Changes (Must Fix)**
- **Suggested Changes (Optional)**

Author knows exactly what's negotiable.

---

### Managing High-Volume Author Relationships

**If you're primary editor for specific authors:**

**Build Working Relationship:**
- Learn their strengths/weaknesses
- Adjust feedback style to what works for them
- Celebrate improvement ("Your ELL scaffolds have gotten so much stronger!")
- Provide consistent standards (don't randomly get stricter/looser)

**Pattern Recognition:**
- Note recurring issues across submissions
- Suggest one-time targeted support rather than repeating same feedback
- "I notice scaffold specificity has been an issue on your last 3 lessons. Would a 30-min training on ELPS scaffolds help?"

**Efficiency:**
- Authors who produce consistent quality may need shorter reviews
- Authors who struggle may need more upfront check-ins during drafting
- Adjust your process based on author track record

---

### When to Escalate to Supervisor

**Escalate immediately if:**
- Author refuses required change after clear explanation
- Author becomes hostile, makes personal attacks
- You're being asked to lower standards for political/business reasons
- Conflict with another editor about standards
- You're unsure if issue is negotiable
- Pattern of poor quality from author (after 3-4 submissions)
- Timeline pressure creating quality/deadline conflict

**How to Escalate:**
- Document the issue with specifics
- Include KB references showing your rationale
- Propose potential solutions
- Be objective (facts, not emotions)

**Example Escalation Email:**
"I need guidance on [Author]'s [content]. They're refusing to add ELPS scaffolds (required for TX adoption per /districts/texas/language/elps-alignment.md). They argue scaffolds aren't needed for 'simple' content. I've explained requirement twice with KB references. Request supervisor conversation with author about non-negotiable requirements."

---

### Self-Care and Emotional Labor

**Editorial Work Is Emotionally Demanding:**
- Making judgments all day
- Managing others' frustration/defensiveness
- Being "the bad guy" who rejects work
- Cognitive load of complex standards

**Strategies:**
1. **Separate work from self-worth:** A tough conversation doesn't mean you failed
2. **Debrief difficult interactions:** With colleague or supervisor
3. **Celebrate wins:** Note author improvements, approvals
4. **Set boundaries:** Don't respond to hostile messages immediately (take a break)
5. **Vary your work:** Don't do difficult reviews back-to-back
6. **Professional development:** Learn conflict resolution, giving feedback

**Remember:**
- You're maintaining quality standards (essential role)
- You're helping authors improve (teaching role)
- Difficult conversations come with the job
- You don't need to be liked by everyone
- You do need to be respected and professional

---

## 9. State Compliance Deep Dives

### Overview

State compliance is **non-negotiable** - content cannot be sold in a state without meeting adoption criteria. This section provides detailed guidance for Texas, California, and Florida.

**Key Principle:** When in doubt about state requirements, reference KB files and escalate to supervisor. Don't guess.

---

### Texas Compliance

#### SBOE Quality Rubric (5 Criteria)

**Location:** `/districts/texas/compliance/sboe-quality-rubric.md`

**Criterion 1: TEKS Alignment**
- **What it means:** Comprehensive coverage of all TEKS listed in scope
- **How to verify:**
  - Cross-reference content brief with TEKS in KB file
  - Check that each TEKS is explicitly addressed (not implied)
  - Verify depth matches TEKS expectation (process vs conceptual understanding)
  - Ensure assessments test the TEKS taught
- **Common failures:**
  - TEKS listed but not actually taught
  - Surface-level coverage of deep standards
  - Assessment misalignment

**Criterion 2: Instructional Design**
- **What it means:** Gradual release, formative assessment, differentiation
- **How to verify:**
  - Trace I do → We do → You do structure
  - Count formative checks (should be every 10-15 min)
  - Check for scaffolds (below grade) and extensions (above grade)
- **Common failures:**
  - Jumping straight to independent practice
  - No formative assessment
  - Generic differentiation ("use manipulatives")

**Criterion 3: Assessment Quality**
- **What it means:** Aligned, varied types, appropriate rigor
- **How to verify:**
  - Each item tests a taught standard
  - Mix of selected response and constructed response
  - DOK levels match standards
  - Answer key is complete and correct
- **Common failures:**
  - Testing untaught skills
  - All one item type
  - Answer key errors

**Criterion 4: Support for ELLs**
- **What it means:** Explicit ELPS integration with scaffolds
- **How to verify:**
  - ELPS standards explicitly listed
  - Three proficiency levels addressed (Beginning, Intermediate, Advanced)
  - Scaffolds are specific and implementable
  - Sentence frames provided
- **Common failures:**
  - "Provide support as needed" (not specific)
  - Only one proficiency level addressed
  - No sentence frames

**Criterion 5: Support for Diverse Learners**
- **What it means:** UDL principles, scaffolds, extensions
- **How to verify:**
  - Multiple means of representation (visual + verbal)
  - Multiple means of expression (choice in output)
  - Specific scaffolds for struggling learners
  - Genuine extensions (not just "more problems")
- **Common failures:**
  - Only one way to learn/demonstrate
  - Generic scaffolds
  - Extensions are just quantity, not complexity

---

#### IPACC Suitability Requirements

**Location:** `/districts/texas/compliance/ipacc-suitability-requirements.md`

**What it covers:**
- Content restrictions (prohibited topics/approaches)
- Factual accuracy requirements
- Age-appropriateness
- Bias-free content

**Key Red Flags:**
- Political bias or advocacy
- Religious content (unless comparative world religions)
- Factual errors
- Inappropriate for grade level
- Stereotypes or bias

**Review Process:**
- Read with IPACC lens (would this be challenged?)
- Check factual accuracy (especially science, history, current events)
- Apply CEID framework for bias
- Err on side of caution for sensitive topics

---

#### Texas-Specific Checklist

For every Texas content review:

- [ ] All TEKS from brief addressed comprehensively
- [ ] ELPS standards explicitly listed and addressed
- [ ] Three ELL proficiency levels scaffolded (B, I, A)
- [ ] Gradual release structure clear
- [ ] Formative assessment every 10-15 minutes
- [ ] Differentiation for below/on/above grade
- [ ] Assessment items test taught TEKS at appropriate DOK
- [ ] Answer key complete and independently verified
- [ ] No IPACC red flags (bias, factual errors, inappropriate content)
- [ ] SBOE Criteria 1-5 all met

---

### California Compliance

#### Adoption Criteria

**Location:** `/districts/california/compliance/california-adoption-criteria.md`

**Key Requirements:**

**1. Standards Alignment (CCSS/NGSS)**
- **What it means:** Comprehensive coverage, appropriate depth
- **How to verify:**
  - All CCSS/NGSS from brief addressed
  - Depth matches "what students who demonstrate understanding can do" descriptors
  - Science: All 3 dimensions addressed (SEPs, DCIs, CCCs)
- **CA Difference from TX:** CCSS is less prescriptive about how to teach; focus on end goals

**2. ELD Standards Integration**
- **What it means:** Explicit support for three proficiency levels
- **How to verify:**
  - ELD standards listed (Part I: Interacting, Interpret, Collaborative)
  - Three levels: Beginning, Intermediate, Bridging (not Emerging, Expanding, Bridging - that's for K-2)
  - Scaffolds differentiated by level
  - Sentence frames for academic discourse
- **CA-Specific:** ELD is integrated, not a separate section
- **Common failures:**
  - Using ELPS language in CA content (wrong framework)
  - Only addressing one proficiency level
  - "Support as needed"

**3. Instructional Design**
- **What it means:** Evidence-based practices, student-centered
- **How to verify:**
  - Active learning strategies
  - Collaborative structures
  - Formative assessment embedded
  - Student agency and choice
- **CA Philosophy:** Constructivist, inquiry-based (more than TX)

**4. Content Suitability**
- **What it means:** Appropriate, accurate, bias-free
- **How to verify:**
  - Age-appropriate complexity
  - Factually accurate
  - CEID framework applied
  - Environmental awareness (CA values this)
  - Diversity and inclusion
- **CA Sensitivities:**
  - Environmental issues (climate change is real and human-caused)
  - Diversity and inclusion (strong emphasis)
  - Indigenous peoples (respectful, accurate representation)

---

#### CA-Specific Checklist

For every California content review:

- [ ] CCSS or NGSS standards comprehensively addressed
- [ ] For science: All 3 dimensions present (SEPs, DCIs, CCCs)
- [ ] ELD standards explicitly listed (Part I categories)
- [ ] Three ELD proficiency levels scaffolded (Beginning, Intermediate, Bridging)
- [ ] Sentence frames for academic discourse
- [ ] Student-centered, inquiry-based approaches
- [ ] Collaborative learning structures
- [ ] Environmental awareness (if relevant to content)
- [ ] Diverse and inclusive representation
- [ ] No content suitability issues
- [ ] CA adoption criteria met

---

### Florida Compliance

#### Statutory Requirements

**Location:** `/districts/florida/compliance/florida-adoption-criteria.md`

**Florida Statutes 1006.31-1006.40** govern instructional materials.

**Key Requirements:**

**1. Standards Alignment (B.E.S.T. or MAFS or NGSSS)**
- **What it means:** Comprehensive, accurate alignment
- **How to verify:**
  - All standards from brief addressed
  - B.E.S.T. (Benchmarks for Excellent Student Thinking) for ELA
  - MAFS (Mathematics Florida Standards) for Math
  - NGSSS (Next Generation Sunshine State Standards) for Science
  - Depth and complexity appropriate
- **FL Difference:** B.E.S.T. is newer, emphasizes civics literacy

**2. ESOL/WIDA Standards**
- **What it means:** Support for English learners
- **How to verify:**
  - ESOL strategies appropriate for content
  - Or WIDA standards addressed
  - Three proficiency levels (Beginning, Intermediate, Advanced)
  - Specific scaffolds, not generic
- **FL Framework:** ESOL is the state framework; many districts use WIDA
- **Check curriculum config** to see which framework applies

**3. Factual Accuracy**
- **What it means:** Content is correct, up-to-date
- **How to verify:**
  - Cross-reference claims with authoritative sources
  - Especially critical for science, history, civics
  - Math: Verify procedures and answers
- **FL Emphasis:** Strong focus on accuracy (legislatively mandated)

**4. Age-Appropriateness**
- **What it means:** Suitable for grade level
- **How to verify:**
  - Reading level appropriate
  - Concepts developmentally appropriate
  - No inappropriate topics for age
- **FL Sensitivities:** Strong emphasis on parent rights and age-appropriateness

**5. Free from Bias**
- **What it means:** CEID-compliant
- **How to verify:**
  - Apply CEID 11 categories
  - No stereotypes
  - Inclusive representation
- **FL Context:** Politically sensitive state; avoid any perception of bias

---

#### FL-Specific Checklist

For every Florida content review:

- [ ] B.E.S.T./MAFS/NGSSS standards comprehensively addressed
- [ ] ESOL or WIDA standards addressed
- [ ] Three ELL proficiency levels scaffolded (B, I, A)
- [ ] Factual accuracy verified (especially science, history, civics)
- [ ] Age-appropriate for grade level
- [ ] No bias or stereotypes (CEID-compliant)
- [ ] Civics literacy addressed (if ELA content)
- [ ] Parent notification for sensitive topics (if applicable)
- [ ] Florida Statutes 1006.31-1006.40 requirements met
- [ ] FL adoption criteria met

---

### Cross-State Considerations

#### When Content Will Be Used in Multiple States

**Challenge:** Meeting TX, CA, and FL requirements simultaneously.

**Strategies:**

**1. Use Most Restrictive Requirements**
- If TX requires ELPS and CA requires ELD, include both
- If FL requires civics literacy and TX doesn't, include it (doesn't hurt TX)
- If CA requires inquiry and TX requires direct instruction, include both approaches

**2. Modular Design**
- Core lesson works for all states
- State-specific modules can be swapped
- Example: Same math lesson, different language scaffolds for TX (ELPS) vs CA (ELD)

**3. Clear Documentation**
- Label state-specific sections
- Provide state-specific guidance in teacher notes
- Make it easy for production to create state versions

**4. Review Order**
- Start with most restrictive state
- Then verify other states' requirements are also met
- Document where requirements conflict (escalate if needed)

---

### State Compliance Red Flags

**Immediate Rejection Reasons:**

**Texas:**
- ELPS standards not addressed
- TEKS not comprehensively covered
- IPACC violations (bias, factual error)

**California:**
- ELD standards not addressed
- CCSS/NGSS coverage incomplete
- Environmental issues misrepresented

**Florida:**
- B.E.S.T./MAFS standards not addressed
- ESOL/WIDA not addressed
- Factual inaccuracies
- Age-inappropriate content

**Any State:**
- Bias or stereotypes (CEID violations)
- Accessibility violations (WCAG 2.1 AA)
- Answer key errors
- Missing required scaffolds for ELL students

---

### When to Consult State Experts

**Escalate to state compliance expert when:**
- Content addresses politically sensitive topic
- Unsure if content violates state statute
- Author disputes state requirement
- Multiple states have conflicting requirements
- Content is innovative/non-traditional (may not fit criteria clearly)

**Don't guess on state compliance** - when in doubt, escalate.

---

## 10. Editor Self-Review and Calibration

### Why Self-Review Matters

**Key Principle:** Editors need quality assurance too.

**Benefits:**
- Catch your own errors before authors find them
- Improve review skills continuously
- Maintain consistent standards
- Build credibility with authors
- Reduce re-review time

**Reality:** Everyone makes mistakes. Self-review minimizes them.

---

### Self-Review Checklist (After Completing Review)

Before submitting your feedback to author, ask yourself:

#### Accuracy Check
- [ ] Did I independently verify the answer key? (Solved every problem myself)
- [ ] Did I open and read the relevant KB files? (Not just rely on memory)
- [ ] Did I check the correct state/grade/subject KB files?
- [ ] Are my KB file references accurate? (Line numbers, file paths)
- [ ] Did I verify standards in the standards alignment KB file?

#### Completeness Check
- [ ] Did I review all 8 sections of the checklist?
- [ ] Did I check every image for alt text?
- [ ] Did I verify all three ELL proficiency levels are addressed?
- [ ] Did I check both required and suggested changes?
- [ ] Did I review the entire document? (Not just skip to sections I care about)

#### Clarity Check
- [ ] Are my comments specific? (Line numbers, exact fixes)
- [ ] Did I explain WHY changes are needed? (Not just WHAT)
- [ ] Are KB references included?
- [ ] Can author implement my feedback without guessing?
- [ ] Did I distinguish required vs suggested changes?

#### Tone Check
- [ ] Did I start with genuine strengths?
- [ ] Is my tone professional and supportive?
- [ ] Did I avoid sarcasm or frustration?
- [ ] Did I calibrate tone to author experience level?
- [ ] Would I want to receive this feedback?

#### Judgment Check
- [ ] Am I being consistent with previous reviews?
- [ ] Am I enforcing KB standards (not personal preferences)?
- [ ] Did I approve/reject based on criteria (not mood)?
- [ ] Am I being fair to this author compared to others?
- [ ] When in doubt, did I verify rather than guess?

**Time Investment:** 5-10 minutes
**Payoff:** Fewer author questions, fewer mistakes, stronger credibility

---

### Calibration: Maintaining Consistency

**Calibration** = Ensuring all editors apply standards consistently.

**Why It Matters:**
- Authors get confused if editors disagree
- Inconsistency undermines author trust
- Quality varies if standards interpretations vary
- Team efficiency suffers without shared understanding

---

#### Calibration Exercise: Reviewing Sample Content as Team

**Frequency:** Monthly or quarterly (depending on team size/needs)

**Process:**

**Step 1: Prepare (1 day before)**
- Select 1-2 pieces of content (mix of strong and weak)
- All editors review independently using full checklist
- Each editor documents decisions and rationale

**Step 2: Compare (During calibration session)**
- Share ratings: Approve, Minor Changes, Major Revisions?
- Identify disagreements
- Discuss rationale for each decision
- Reference KB files together
- Reach consensus on correct standard

**Step 3: Document (After session)**
- Record decisions for future reference
- Update FAQ or editor notes if needed
- Flag KB ambiguities for maintainers

**Step 4: Apply (Ongoing)**
- Use agreed-upon interpretations in reviews
- Reference calibration decisions when uncertain

**Example Calibration Questions:**
- How specific must ELL scaffolds be to pass?
- When is "close enough" acceptable for instructional routines?
- How many formative checks are sufficient?
- What constitutes a "critical" vs "minor" issue?
- When do we approve with minor changes vs require revision?

---

#### Self-Calibration: Checking Your Own Consistency

**Exercise:** Review your last 5-10 reviews. Ask:

**Consistency Questions:**
1. **Standards Applied:**
   - Am I enforcing the same standards across all reviews?
   - Or am I stricter on some authors/topics?
   - Pattern: Same issue gets different treatment?

2. **Time Spent:**
   - Similar content types taking similar time?
   - Or am I rushing some, over-analyzing others?
   - Pattern: Review time wildly inconsistent?

3. **Tone:**
   - Is my feedback tone consistent?
   - Or am I harsher on Mondays, more lenient on Fridays?
   - Pattern: Mood affecting reviews?

4. **Approval Rates:**
   - What % require major revision vs minor changes vs approved?
   - Is it consistent or varying widely?
   - Pattern: Too strict (everything fails) or too lenient (everything passes)?

**Healthy Patterns:**
- 20-30% Approved first submission
- 40-50% Minor changes needed
- 20-30% Major revision needed
- (Will vary by author experience and content complexity)

**Red Flags:**
- 0% approvals (too strict?) or 90% approvals (too lenient?)
- Wildly different treatment of same issue across reviews
- Time spent varying by 3x for similar content
- Tone changes based on author identity

---

### Peer Review: Learning from Other Editors

**Shadow Experienced Editors:**
- Watch them review content
- Ask about decision-making process
- Note how they use KB files
- Observe feedback tone and structure

**Reverse Shadow:**
- Have experienced editor watch you review
- Get feedback on your process
- Identify blind spots
- Learn efficiency tricks

**Buddy System:**
- Partner with another editor
- Review same content independently
- Compare notes and discuss differences
- Build shared understanding

**Second-Eye Review (for complex/sensitive content):**
- Request another editor review before sending feedback
- Especially useful for:
  - Your first few reviews
  - Politically sensitive content
  - Author disputes your feedback
  - You're uncertain about decision

---

### Continuous Improvement Strategies

#### 1. Track Your Patterns

**Keep a log:**
- Date, content type, time spent, outcome (approved/changes/major revision)
- Issues you flagged
- Author response (accepted/pushed back)
- Things you missed (caught later)

**Review quarterly:**
- What types of issues do I consistently catch?
- What types do I consistently miss?
- Where do authors most often push back?
- Where am I spending disproportionate time?

**Adjust:**
- Create personal checklist for commonly-missed items
- Set time limits for reviews
- Study KB files for weak areas

---

#### 2. Learn from Mistakes

**When you make an error:**
- Don't beat yourself up (everyone makes mistakes)
- Analyze: WHY did I miss this?
  - Rushed? Distracted? Unfamiliar KB file? Misread?
- Create a reminder/checklist item to prevent recurrence
- Share learning with team (if helpful)

**Common Editor Errors:**
- Skipping answer key verification (relying on author)
- Not opening KB files (relying on memory)
- Missing images without alt text (visual content easy to overlook)
- Not checking all three ELL proficiency levels
- Approving vague scaffolds ("provide support as needed")
- Missing bias/stereotypes (not applying CEID systematically)

**Prevention:**
- Use self-review checklist EVERY time
- Never skip steps when tired/rushed
- When in doubt, verify (don't assume)

---

#### 3. Seek Feedback on Your Feedback

**Ask authors:**
- "Was my feedback clear and actionable?"
- "What could I have explained better?"
- "Did you understand the rationale for changes?"

**Ask supervisor:**
- "How's my review quality?"
- "Any patterns you've noticed?"
- "Areas for improvement?"

**Ask peers:**
- "Can you review my feedback before I send it?"
- "How would you have handled [situation]?"

---

#### 4. Professional Development

**Invest in growth:**
- Attend workshops on educational standards
- Read research on instructional practices
- Take courses in UDL, accessibility, cultural responsiveness
- Join professional organizations (e.g., learning engineering societies)
- Stay current on state adoption changes

**Deepen KB knowledge:**
- Read all KB files thoroughly (not just when needed for review)
- Study instructional routines in depth
- Learn about standards frameworks beyond your comfort zone
- Understand the "why" behind requirements (not just "what")

**Build subject expertise:**
- Partner with subject matter experts
- Take refresher courses in content areas
- Read grade-level textbooks to understand student perspective
- Shadow teachers using the content

---

### Self-Assessment: Am I a Strong Editor?

**Signs of Strong Editorial Practice:**

✅ I independently verify answer keys for every review
✅ I reference KB files regularly (not just for first few reviews)
✅ I provide specific, actionable feedback with line numbers
✅ I explain the "why" behind required changes
✅ I distinguish between required and suggested changes clearly
✅ My feedback tone is professional, supportive, and calibrated to author
✅ Authors rarely ask "what do you mean?" (clarity high)
✅ My review times are consistent for similar content types
✅ I apply same standards regardless of author identity or my mood
✅ I admit mistakes quickly and professionally
✅ I escalate when unsure (don't guess on state compliance)
✅ I participate in calibration exercises
✅ I seek continuous improvement
✅ Authors trust my expertise (even when they disagree)
✅ Other editors seek my input on difficult reviews

**Signs of Struggling Editorial Practice:**

❌ I often skip verifying answer keys (trust author)
❌ I rely on memory rather than opening KB files
❌ My feedback is vague ("needs work," "improve this")
❌ Authors frequently ask for clarification
❌ I don't distinguish required vs suggested (everything sounds required)
❌ My tone varies widely by day/author
❌ My review times are wildly inconsistent
❌ I realize I'm stricter with some authors than others
❌ I defend incorrect feedback rather than admit mistakes
❌ I guess on state requirements (don't verify)
❌ I avoid calibration (don't want to be judged)
❌ Authors push back frequently on my feedback
❌ Other editors question my decisions regularly

**If you identify with "struggling" signs:**
- Don't panic - these are learnable skills
- Talk to supervisor about support/training
- Use self-review checklist religiously
- Shadow experienced editors
- Slow down (quality > speed)

---

### Building Editorial Expertise: 3-Month Roadmap

**Month 1: Build Foundations**
- Use self-review checklist on EVERY review
- Open and read KB files (don't rely on memory)
- Shadow experienced editor (2-3 reviews)
- Participate in calibration exercise
- Goal: Consistency and accuracy

**Month 2: Develop Efficiency**
- Track review times, identify where you're slow
- Build personal shortcuts (bookmarks for KB files, feedback templates)
- Practice providing feedback faster (without sacrificing quality)
- Request peer review on 2-3 of your reviews
- Goal: Efficiency without compromising quality

**Month 3: Deepen Expertise**
- Study KB files for areas you're less familiar with
- Take on more complex content (if available)
- Mentor newer editor (teaching solidifies learning)
- Contribute to team calibration discussions
- Goal: Become go-to resource for specific areas

**Ongoing:**
- Quarterly self-assessment
- Continuous KB study
- Professional development (workshops, courses)
- Seek feedback from authors, peers, supervisor

---

## 11. Workload and Time Management

### Understanding Editorial Workload

**Typical Review Times:**
- **Lessons:** 1.5-3 hours (detailed review)
- **Assessments:** 1-2 hours (detailed review)
- **Activities:** 30-60 minutes
- **Preliminary reviews:** 15-30 minutes
- **Re-reviews:** 30-60 minutes

**Factors Affecting Time:**
- Content quality (weak content takes longer)
- Content complexity
- Your familiarity with topic/state
- Author experience level (more feedback needed for new authors)
- Number of issues to document

**Realistic Daily Capacity:**
- **Experienced editors:** 2-3 full lesson reviews OR 4-5 assessment reviews
- **New editors (first 3 months):** 1-2 lesson reviews OR 2-3 assessment reviews
- **Mix:** Adjust based on content complexity

---

### Time Management Strategies

#### 1. Time-Boxing Reviews

**Problem:** Reviews can expand indefinitely ("just one more thing to check...")

**Solution:** Set timer for estimated time

**Process:**
1. **Estimate:** Based on content type, assign time budget
   - Lesson: 2 hours
   - Assessment: 1.5 hours
   - Activity: 45 minutes
2. **Set timer:** Use actual timer or schedule block
3. **Work efficiently:** Focus on 8-section checklist systematically
4. **At time limit:**
   - If nearly done: Finish (add 15 min max)
   - If far from done: Note where you are, take break, resume
5. **Track:** Note actual time spent
6. **Analyze:** If consistently over, discuss with supervisor

**Benefits:**
- Prevents perfectionism
- Maintains consistent pace
- Identifies content that genuinely needs more time vs over-analysis

---

#### 2. Batching Similar Work

**Problem:** Constant context-switching drains energy

**Solution:** Group similar types of reviews

**Strategies:**
- **Morning:** Complex/difficult reviews (when fresh)
- **Afternoon:** Simpler reviews or re-reviews
- **Same-state batching:** Review all TX content together (KB files fresh in mind)
- **Same-subject batching:** Review all math content together
- **Same-author batching:** If reviewing multiple pieces from one author

**Benefits:**
- Reduces mental load of switching contexts
- KB files stay fresh in memory
- More efficient

---

#### 3. Prioritization Matrix

**When you have multiple reviews:**

**Priority 1 (Do First):**
- Deadline today or tomorrow
- Author blocked (can't proceed without your review)
- Simple content (quick win)
- Revision cycles (author waiting)

**Priority 2 (Do Soon):**
- Deadline this week
- Standard review requests
- Complex content (needs focused time)

**Priority 3 (Do Later):**
- Deadline next week+
- Optional reviews
- "Nice to have" second-eye reviews

**Priority 4 (Delegate/Decline):**
- Outside your expertise (needs SME)
- Workload unsustainable (escalate to supervisor)
- Not your assigned content

**Tool:** Use kanban board or simple list to track

---

#### 4. The Two-Pass Review

**For very long or complex content:**

**Pass 1: Skim (15-30 min)**
- Quick scan for obvious issues
- Check completeness (all sections present?)
- Verify answer key exists
- Assess overall quality (strong/weak/average)
- Decide: Worth detailed review now, or return to author for obvious fixes first?

**Benefits:**
- Catches major issues early
- Avoids spending 2 hours on fundamentally flawed content
- Author can fix obvious issues before you do detailed review

**Pass 2: Detailed Review (1-2 hours)**
- Full 8-section checklist
- Line-by-line feedback
- KB file verification
- Complete review

**When to use:**
- First-time authors (content may be very rough)
- Unfamiliar content type
- Tight timeline (need to triage)

---

### Managing High-Workload Periods

#### When Backlog Is Growing

**Step 1: Assess (15 min)**
- How many reviews pending?
- What are deadlines?
- What's realistic capacity?
- How far behind are you?

**Step 2: Communicate (30 min)**
- Email supervisor with situation
- Provide specific numbers ("10 reviews pending, can complete 3/day, need 4 days")
- Propose solutions (see below)
- Request help

**Step 3: Triage**
- Use prioritization matrix
- Focus on P1 items only
- Delay P3/P4 items
- Be transparent with authors about timelines

**Solutions to Propose:**
- Deadline extensions for lower-priority reviews
- Additional editor support (if available)
- Declining new assignments temporarily
- Simplified review for low-risk content (preliminary only)

**What NOT to do:**
- Silently work excessive hours (unsustainable)
- Rush reviews and miss issues (damages quality)
- Approve without reviewing (violates standards)

---

#### Preventing Overload

**Strategy 1: Track Workload Weekly**
- Monday: Note pending reviews and deadlines
- Daily: Update as you complete/receive new
- Friday: Assess next week's capacity
- Proactively communicate if overloaded

**Strategy 2: Set Boundaries**
- Define work hours (e.g., 9am-5pm, no evenings)
- Communicate availability to authors
- Block calendar for deep work (review time)
- Decline unreasonable deadlines early

**Strategy 3: Build Buffer Time**
- Don't schedule at 100% capacity
- Allow 20% buffer for unexpected delays (sick days, complex reviews, urgent requests)
- Example: If you can do 15 reviews/week, commit to 12

**Strategy 4: Negotiate Realistic Timelines**
- When new content assigned: Estimate review time honestly
- If deadline is unrealistic: Say so immediately (not day before deadline)
- Propose alternative: "I can review by Friday, not Tuesday"

---

### Efficiency Without Sacrificing Quality

#### Time-Savers (Good Practices)

**1. Template Feedback**
- Save common feedback snippets
- Example: "Learning objective should be measurable. Try [Bloom's verb] instead of 'understand.' See AUTHOR_GUIDE.md Section 6.1."
- Personalize when pasting (add specifics)

**2. KB File Bookmarks**
- Bookmark frequently-used KB files in browser
- Create shortcuts/aliases for quick access
- Keep KB repository cloned locally

**3. Checklists**
- Print or save 8-section checklist
- Check off as you go (ensures nothing skipped)
- Add personal items for things you commonly miss

**4. Dual Monitors**
- Content on one screen, KB files on other
- Reduces switching time

**5. Keyboard Shortcuts**
- Learn GitHub shortcuts for commenting
- Use text expander for common phrases
- Speed up navigation

**6. Review in Order**
- Follow same sequence every time (reduces forgotten items)
- Start Section 1, end Section 8
- Build muscle memory

---

#### Time-Wasters (Avoid These)

❌ **Re-reading same section multiple times** (skim once, detail once, done)
❌ **Over-researching** (if KB doesn't cover it, escalate - don't Google for hours)
❌ **Perfectionism** ("good enough" beats "perfect")
❌ **Rewriting author's content** (provide feedback, let them revise)
❌ **Debating with author asynchronously** (10 messages back-and-forth - just hop on a call)
❌ **Checking email during review** (focus time = faster reviews)
❌ **Not using self-review checklist** (results in re-work when you miss something)

---

### Signs of Unsustainable Workload

**Physical Signs:**
- Consistently working evenings/weekends
- Skipping lunch to review content
- Fatigue, headaches, eye strain
- Sleep disruption

**Performance Signs:**
- Review quality declining
- Missing issues you'd normally catch
- Taking longer than usual for same content
- Making careless errors

**Emotional Signs:**
- Dreading reviews
- Feeling resentful toward authors
- Cynicism about content quality
- Irritability with colleagues/family

**Behavioral Signs:**
- Cutting corners (skipping answer key checks)
- Avoiding difficult conversations
- Procrastinating on reviews
- Isolating from team

**If you identify 3+ signs: Escalate to supervisor immediately.**

---

### Sustainable Editorial Practice

**Weekly Rhythm:**

**Monday:**
- Review pending assignments
- Prioritize for week
- Communicate any timeline concerns
- Start with complex review (fresh mind)

**Tuesday-Thursday:**
- Focus on detailed reviews
- Batch similar content
- Take breaks between reviews (15 min)
- Lunch away from desk

**Friday:**
- Complete re-reviews (shorter)
- Catch up on author questions
- Plan next week
- Reflect on week (what went well, what to improve)

**Work-Life Boundaries:**
- Define work hours, stick to them
- No reviews on weekends (unless emergency + approved by supervisor)
- Take vacation time
- Disconnect after hours

**Energy Management:**
- Most complex work when you're fresh (morning for most people)
- Breaks every 90 minutes
- Physical movement between reviews
- Vary work (don't do 6 reviews back-to-back)

---

### Career Sustainability

**Longevity in editorial work requires:**

**1. Setting Realistic Standards for Yourself**
- You can't catch every issue
- Perfection is impossible
- "Good enough" is actually good enough
- You're human, you'll make mistakes

**2. Continuous Learning**
- Professional development prevents boredom/stagnation
- Deepening expertise makes reviews easier
- Building new skills opens opportunities

**3. Team Connection**
- Don't work in isolation
- Share challenges and wins
- Calibrate regularly
- Ask for help when needed

**4. Celebrating Wins**
- Authors improving over time
- Approval moments
- Catching critical issues before publication
- Mentor successes

**5. Advocacy for Reasonable Workload**
- Speak up when overloaded
- Propose solutions
- Track data (X reviews/week sustainable, Y is not)
- Don't suffer in silence

**Editorial work is intellectually demanding. Sustainable practice protects both you and content quality.**

---

## Quick Reference

### Knowledge Base Locations

**Universal:**
- `/universal/frameworks/` - UDL, DOK, EB, sentence frames
- `/universal/assessment/` - Item types, rubrics, keys
- `/universal/accessibility/` - WCAG
- `/universal/content-equity/` - CEID

**Subject-Common:**
- `/subjects/mathematics/common/mlr/` - MLRs
- `/subjects/ela/common/literacy-routines/` - Literacy routines
- `/subjects/science/common/` - NGSS, practices

**District-Wide:**
- `/districts/texas/` - ELPS, SBOE, IPACC
- `/districts/california/` - ELD, adoption criteria
- `/districts/florida/` - ESOL, adoption criteria

**Subject-District:**
- `/subjects/[subject]/districts/[state]/` - Standards alignment

### Review Times

- **Preliminary Review:** 15-30 min
- **Detailed Review:** 1-3 hours (lessons), 1-2 hours (assessments)
- **Feedback Writing:** 30-60 min
- **Re-Review:** 30-60 min

### Common Actions

**Approve:**
```bash
# In GitHub PR
1. Click "Review changes"
2. Select "Approve"
3. Click "Submit review"
4. Click "Merge pull request"
```

**Request Changes:**
```bash
# In GitHub PR
1. Add line comments on specific issues
2. Add general comment with summary
3. Click "Review changes"
4. Select "Request changes"
5. Click "Submit review"
```

---

## 12. Frequently Asked Questions

### General Editorial Questions

**Q1: How long should a typical review take?**

**A:** Depends on content type and complexity:
- **Lessons:** 1.5-3 hours for detailed review
- **Assessments:** 1-2 hours for detailed review
- **Activities/Resources:** 30-60 minutes
- **Preliminary reviews:** 15-30 minutes

If you're consistently over these times, discuss with your supervisor. You may need calibration or the content may have unusual complexity.

---

**Q2: What if the author is resistant to feedback?**

**A:** See Section 8 (Difficult Conversations). Short answer:
1. Stay professional and reference KB files
2. Explain the "why" behind requirements
3. Distinguish between required (non-negotiable) and suggested changes
4. Escalate to supervisor if author refuses required changes
5. Remember: You're the guardian of quality standards

---

**Q3: Can I approve content that's "good enough" even if not perfect?**

**A:** Yes, if:
- All **required** changes are addressed (7 Quality Pillars met)
- Minor suggestions can be skipped if author has good rationale
- Content meets adoption criteria for target state
- No compliance violations remain

Balance perfection with practicality. "Perfect is the enemy of done."

---

**Q4: What do I do if I disagree with the knowledge base guidance?**

**A:** KB files represent organizational standards and research-based practices:
1. **For clarity issues:** Create issue in KB repository with specific question
2. **For missing guidance:** Suggest addition to KB maintainers
3. **For current review:** Follow KB as written (consistency > individual preference)
4. **Don't:** Override KB guidance in your review without approval

---

**Q5: How do I handle content from a senior author who makes mistakes?**

**A:** Experience doesn't equal infallibility:
1. Review with same standards (no passes for seniority)
2. Tone can be collegial: "I noticed X - can we fix?" vs "You need to fix X"
3. Reference KB files (not personal opinion)
4. If pattern of issues, discuss with supervisor privately
5. Remember: Quality standards apply to everyone

---

### Knowledge Base Questions

**Q6: Do I need to open every KB file for every review?**

**A:** Not every time, but frequently:
- **First 10 reviews:** Yes, open everything to build familiarity
- **After that:** Open when:
  - You're unsure about a requirement
  - Content uses unfamiliar routine/protocol
  - Author claims KB says something you don't remember
  - State-specific requirements (always verify)

Build mental library over time, but verify don't assume.

---

**Q7: What if the KB file and the content both seem wrong?**

**A:**
1. **Verify you have the correct KB file** (easy to grab wrong state/grade)
2. **Read KB file completely** (answer often in context)
3. **If KB genuinely has error:** Flag for KB maintainers but use current KB for this review
4. **If content contradicts KB:** Content is wrong (KB is source of truth)

---

**Q8: The author says they got the information from a different source. Do I still enforce the KB?**

**A:** Yes. KB represents organizational standards:
- KB may differ from other publishers (that's okay)
- KB may differ from what author learned in training (KB wins)
- KB reflects HMH's instructional philosophy
- Consistency across content is critical

If author has compelling research, they can propose KB update. For this content, follow KB.

---

### Standards and Alignment Questions

**Q9: How do I verify standards alignment if I'm not a subject matter expert?**

**A:** You don't need to be a content expert:
1. **Open the standards KB file** for that state/grade/subject
2. **Read the standard description** in the KB file
3. **Check that lesson objective matches standard verb** (analyze, explain, solve)
4. **Verify practice problems match standard examples** in KB
5. **Check DOK level** matches standard expectation

If still unsure, flag for subject matter expert review.

---

**Q10: What if content addresses a standard not in the brief?**

**A:** Clarify with curriculum lead:
- **Brief may be incomplete** (sometimes happens)
- **Author may have scope creep** (adding unnecessary standards)
- **Standard may be prerequisite** (addressing background knowledge)

Don't approve extraneous standards without confirmation from curriculum lead.

---

**Q11: How strict should I be about DOK levels?**

**A:** Moderately strict:
- **DOK 1 assessment for DOK 3 standard:** FAIL (too easy)
- **DOK 3 assessment for DOK 2 standard:** Usually okay (challenge is good)
- **Check state requirements:** Some states specify DOK levels for adoption
- **Use judgment:** One slightly off item is minor; all items too easy/hard is critical

---

### Pedagogical Questions

**Q12: What if the instructional routine is "close enough" but not exactly matching the KB file?**

**A:** Depends on deviation:
- **Missing a step:** Required fix
- **Steps out of order:** Required fix
- **Additional step that enhances:** Usually okay (verify doesn't contradict protocol)
- **Different timing:** Okay if reasonable
- **Different facilitation approach:** Flag and discuss (may be innovation or may be error)

Protocols exist for research-based reasons. "Close enough" often isn't.

---

**Q13: Do I need to check answer keys even for simple problems?**

**A:** **YES. ALWAYS.** Answer key errors are:
- Common (even in simple problems)
- Damaging to teacher trust
- Embarrassing to organization
- Easy to prevent

Independently solve every problem. Don't skim. This is non-negotiable.

---

**Q14: What if the lesson works pedagogically but doesn't follow the exact template structure?**

**A:** Template flexibility depends on organization policy:
- **Required sections:** Must be present (objectives, standards, assessment, etc.)
- **Section order:** Usually flexible if logical
- **Additional sections:** Usually okay if they add value
- **Missing sections:** Not okay

Check with supervisor about template flexibility for your organization.

---

### Language Support Questions

**Q15: How do I know if ELL scaffolds are sufficient?**

**A:** Ask these questions:
1. **Could a teacher implement without guessing?** (Specific, not vague)
2. **Are all three proficiency levels addressed?** (Beginning, Intermediate, Advanced)
3. **Are scaffolds differentiated by level?** (Not same scaffold for all levels)
4. **Are sentence frames provided?** (For academic discourse)
5. **Is vocabulary support explicit?** (Not just "pre-teach vocabulary")

If "Provide support as needed" appears anywhere: FAIL. That's not scaffolding.

---

**Q16: What if the author argues that ELL scaffolds aren't needed for "simple" content?**

**A:** All content needs scaffolds:
- "Simple" for native speakers ≠ simple for emergent bilinguals
- State requirements apply to ALL content
- Academic language is challenging even in "simple" content
- Adoption criteria require ELL support throughout

Non-negotiable. Provide specific examples from KB file.

---

**Q17: The sentence frames seem formulaic. Is that okay?**

**A:** Depends on use:
- **For Beginning ELLs:** Structured frames are appropriate
- **For Advanced ELLs:** Should be more flexible/complex
- **Red flag:** Same frame used for every response throughout lesson
- **Good practice:** Multiple frames for same language function, increasing complexity

Check `/universal/frameworks/sentence-frames-library.md` for appropriate progression.

---

### Accessibility Questions

**Q18: How detailed should alt text be?**

**A:** Detailed enough to understand content and function:
- **Decorative images:** alt="" (empty)
- **Simple images:** "Bar graph showing 3 categories: red 45%, blue 30%, green 25%"
- **Complex diagrams:** Brief alt + extended description
- **Functional images:** Describe function ("Click to enlarge image")

Test: Close your eyes, have someone read alt text - can you understand?

---

**Q19: What if the author says "designers will add alt text later"?**

**A:** Not acceptable:
- Author knows content best (what should alt text say?)
- Production may not have content expertise
- Alt text is content, not design
- Author responsible for accessibility

Require alt text descriptions in content submission. Production can format, but author must provide.

---

**Q20: Do I need to check color contrast if content is in black and white?**

**A:** Check for final format:
- **Print-only content:** Usually okay (but check grayscale readability)
- **Digital content:** Must check (especially if color will be added in production)
- **Charts/graphs:** Must have patterns or labels (not just color coding)

Better to flag potential issues early than fix in production.

---

### Cultural Responsiveness Questions

**Q21: How do I spot subtle bias?**

**A:** Use CEID framework systematically:
1. **List all names:** Are they diverse?
2. **List all family structures:** Is nuclear family assumed?
3. **List all contexts:** Do they assume economic privilege?
4. **Check pronouns and roles:** Are gender roles stereotypical?
5. **Check images:** Is diversity authentic or tokenized?

Read with critical eye: "Would students from [demographic] feel included?"

---

**Q22: What if the bias is minor and the author pushes back?**

**A:** Bias is not minor:
- Small biases accumulate across curriculum
- Students notice exclusion/stereotyping
- Adoption criteria include bias-free content
- Easy to fix (change name, adjust context)

Be firm. Provide specific CEID guideline reference. This is quality standard, not preference.

---

**Q23: Can content include religious holidays?**

**A:** Depends on context:
- **Educational context:** Study of religious holidays as cultural practice (okay)
- **Assumption of participation:** Math problems assuming Christmas celebration (not okay)
- **Secular alternative exists:** Use winter holiday, celebration, event (better)
- **State requirements vary:** Check district KB file

When in doubt, suggest secular alternative.

---

### State Compliance Questions

**Q24: Do I need to memorize state requirements?**

**A:** No, but know where to find them:
- **Texas:** SBOE Quality Rubric (5 criteria), IPACC, ELPS
- **California:** Adoption criteria, ELD Standards
- **Florida:** F.S. 1006.31-1006.40, ESOL/WIDA

Keep state compliance KB files bookmarked. Reference them for every state-specific review.

---

**Q25: What if content meets pedagogical standards but fails state compliance?**

**A:** State compliance is non-negotiable:
- Content can't be sold in that state without compliance
- Adoption criteria are legal requirements
- Pedagogically sound ≠ state compliant

Return for revision with specific compliance requirements cited.

---

### Process Questions

**Q26: Should I approve content with minor typos?**

**A:** Depends on volume:
- **1-2 typos:** Okay to approve, note in comment "Fix typos: line X, line Y"
- **5+ typos:** Request changes (indicates rushed work)
- **Systematic errors:** Request changes (indicates need for careful proofread)

Use judgment. Don't hold up approval for one typo, but don't ignore patterns.

---

**Q27: What if I approved content but then noticed an error?**

**A:** Depends on stage:
- **Not yet published:** Create issue, author can fix
- **In production:** Flag for production team ASAP
- **Already published:** Create errata issue, plan for next revision

Document the error and how it was caught. Helps improve review process.

---

**Q28: How do I handle content that's "almost there" after multiple revision cycles?**

**A:** After 2-3 cycles:
1. **Assess if author is making progress** (improving vs stuck)
2. **Consider synchronous support** (30-min call to clarify)
3. **Evaluate if author has capacity** (may need reassignment)
4. **Document patterns** (for author development planning)
5. **Escalate to supervisor** if stuck

Don't approve substandard content to "end the cycle." Maintain standards.

---

**Q29: Can I edit the content myself to fix small issues?**

**A:** Organization policy varies:
- **Some allow minor edits:** Typos, formatting, punctuation
- **Most require author revision:** Ensures author learns
- **Never acceptable to edit without telling author**

Check your organization's policy. Default: Author makes revisions (they learn more).

---

**Q30: What if I don't have time to do a thorough review?**

**A:** Communicate immediately:
- **Option 1:** Request deadline extension
- **Option 2:** Request another editor (if available)
- **Option 3:** Do preliminary review, note "full review pending"
- **Not acceptable:** Rush through and miss critical issues

Quality cannot be compromised for timeline. Escalate to supervisor.

---

## 13. Troubleshooting Common Challenges

### Challenge 1: Overwhelming Workload

**Symptoms:**
- Reviews consistently taking longer than estimated
- Backlog of content growing
- Quality of reviews declining due to rushing
- Feeling burned out

**Diagnosis:**
- Are you doing unnecessary work? (Reading tangential KB files, over-researching)
- Are assignments realistic for your experience level?
- Is content quality lower than expected? (More revision cycles)

**Solutions:**
1. **Time-box reviews:** Set timer for estimated time, note when you go over
2. **Track patterns:** Which types of content take longest? Why?
3. **Discuss with supervisor:** May need workload adjustment or prioritization
4. **Use templates:** Speed up feedback writing
5. **Build KB familiarity:** Reduces lookup time over time

**When to escalate:** If workload is consistently unsustainable after 1 month.

---

### Challenge 2: Inconsistent Standards Across Editors

**Symptoms:**
- Authors complain "Editor A approved this, but you're rejecting it"
- Your feedback contradicts another editor's
- Confusion about what standards actually require

**Diagnosis:**
- Lack of calibration across editorial team
- Editors interpreting KB files differently
- Unclear organizational policies

**Solutions:**
1. **Request calibration session:** All editors review same content, discuss
2. **Create editor FAQ:** Document common interpretation questions
3. **Consult KB files together:** Resolve ambiguities as team
4. **Review approved examples:** Ensure shared understanding of "good enough"
5. **Document decisions:** When team makes interpretation, add to notes

**When to escalate:** Immediately if affecting author trust or content quality.

---

### Challenge 3: Author Doesn't Understand Feedback

**Symptoms:**
- Author revisions don't address your feedback
- Author asks "What do you mean?" repeatedly
- Revisions introduce new problems while fixing old ones

**Diagnosis:**
- Feedback may be too vague
- Author may lack prerequisite knowledge
- Communication style mismatch

**Solutions:**
1. **Increase specificity:** Provide exact fix, not just "improve this"
2. **Offer examples:** Show before/after
3. **Switch to synchronous:** 15-min call > 5 async exchanges
4. **Provide templates:** "Use this structure exactly"
5. **Check author resources:** Have they read AUTHOR_GUIDE.md?

**When to escalate:** If author doesn't improve after synchronous support.

---

### Challenge 4: Content Requires Expertise You Don't Have

**Symptoms:**
- Unsure if mathematical reasoning is correct
- Can't evaluate if scientific procedure is valid
- Uncertain if historical content is accurate

**Diagnosis:**
- Content exceeds your subject matter expertise
- Normal for generalist editors

**Solutions:**
1. **Flag for SME review:** "I'm not qualified to verify the chemistry here"
2. **Use KB files:** Often contain subject-specific guidance
3. **Consult other editors:** Someone may have relevant background
4. **Approve with caveat:** "Approved pending SME review of sections X, Y"
5. **Build relationship with SMEs:** Quick questions get faster answers

**When to escalate:** Don't approve content you're not qualified to review.

---

### Challenge 5: Tight Deadline vs Quality Standards

**Symptoms:**
- Content needs major revisions but deadline is tomorrow
- Pressure to "just approve it"
- Asked to "lower standards for this one"

**Diagnosis:**
- Planning failure upstream (unrealistic timeline)
- Content quality lower than expected
- Pressure from external stakeholders

**Solutions:**
1. **Communicate early:** "This needs 3 days of revision, deadline is tomorrow"
2. **Prioritize critical issues:** Required changes vs nice-to-haves
3. **Propose compromise:** "We can meet deadline with these 3 fixes, defer these 5"
4. **Document decision:** If standards lowered, note why in writing
5. **Escalate immediately:** Supervisor decides timeline vs quality trade-offs

**What NOT to do:** Silently approve substandard content.

---

### Challenge 6: Author Is Defensive or Hostile

**Symptoms:**
- Author responds with anger to feedback
- Author argues every point
- Author claims you "don't understand"

**Diagnosis:**
- Author may be frustrated (normal response to criticism)
- Communication tone may be mismatched
- Genuine disagreement about standards

**Solutions:**
1. **Stay professional:** Don't match emotional tone
2. **Reference KB files:** Not your opinion, organizational standards
3. **Acknowledge good work:** Start with strengths
4. **Separate required vs suggested:** Focus on non-negotiables
5. **Offer synchronous conversation:** Tone is clearer in voice
6. **Loop in supervisor early:** If hostility continues

**Red flags:** Personal attacks, refusal to engage, pattern across multiple editors.

**When to escalate:** Immediately if hostility continues after one attempt to de-escalate.

---

### Challenge 7: You Made a Mistake in Your Review

**Symptoms:**
- Author correctly points out your feedback was wrong
- You realize you misread KB file
- You caught error after approval

**Diagnosis:**
- Human error (happens to everyone)
- May have been rushed or distracted

**Solutions:**
1. **Acknowledge immediately:** "You're right, I misread that. Approved as is."
2. **Apologize briefly:** "Sorry for confusion" (don't over-apologize)
3. **Correct the record:** Update your feedback/comment
4. **Learn:** What caused error? Tired? Unfamiliar KB file?
5. **Don't be defensive:** Admitting mistakes builds author trust

**What NOT to do:** Double down on wrong feedback to save face.

---

### Challenge 8: Conflicting Guidance in KB Files

**Symptoms:**
- Two KB files seem to contradict
- Unclear which takes precedence
- Author cites different KB file than you

**Diagnosis:**
- May be genuine conflict in KB
- May be misunderstanding scope (state-specific vs universal)
- May be reading out of context

**Solutions:**
1. **Verify hierarchy:** Program-specific > Subject-District > Subject-Common > District > Universal
2. **Read both files completely:** Context often resolves conflict
3. **Check dates:** Newer file may supersede older
4. **Ask KB maintainers:** File issue for clarification
5. **For this review:** Use most specific guidance (per hierarchy)

**Document:** Note the conflict so it can be resolved systemically.

---

### Challenge 9: Repetitive Low-Quality Content from Same Author

**Symptoms:**
- Same issues across multiple submissions
- Author not learning from feedback
- Quality not improving

**Diagnosis:**
- Author may lack prerequisite skills
- Author may not be reading/understanding feedback
- Author may be overwhelmed

**Solutions:**
1. **Review feedback clarity:** Is it specific enough?
2. **Check if author is using AUTHOR_GUIDE.md:** May not know resources exist
3. **Propose targeted training:** Focus on specific gaps
4. **Increase supervision:** More check-ins during drafting (not just at end)
5. **Discuss with supervisor:** May need reassignment or different support

**When to escalate:** After 3-4 submissions with same issues.

---

### Challenge 10: Unsure if Issue Is Critical or Minor

**Symptoms:**
- Can't decide between "Approve with changes" vs "Requires revision"
- Uncertain if issue violates adoption criteria
- Don't know how strictly to enforce guidance

**Diagnosis:**
- Normal for new editors
- Edge case not clearly addressed in KB

**Solutions:**
1. **Check adoption criteria:** Does it violate state requirements? (Critical)
2. **Check 7 Quality Pillars:** Does it fail a pillar? (Critical)
3. **Ask other editors:** How would they classify?
4. **Consider impact:** Would teacher/student struggle without fix? (Critical)
5. **When in doubt, require fix:** Easier to approve later than recall after approval

**Build judgment over time:** You'll develop sense for what's critical.

---

### Challenge 11: Content Is Culturally Sensitive Topic

**Symptoms:**
- Content addresses topics like race, religion, gender, immigration
- Unsure if approach is appropriate
- Worried about getting it wrong

**Diagnosis:**
- Normal concern for sensitive topics
- Need for care and expertise

**Solutions:**
1. **Use CEID guidelines strictly:** Check all 11 categories
2. **Apply "Would this alienate?" test:** For multiple demographics
3. **Check state-specific requirements:** Some states have specific rules
4. **Consult CEID expert if available:** Don't guess on sensitive topics
5. **Look for authentic diverse voices:** Was content reviewed by affected communities?

**When to escalate:** If uncertain about cultural appropriateness, get second opinion.

**Remember:** When in doubt, suggest more inclusive alternative.

---

### Challenge 12: Burnout and Compassion Fatigue

**Symptoms:**
- Feeling cynical about content/authors
- Declining empathy in feedback
- Dreading reviews
- Physical exhaustion

**Diagnosis:**
- Common in sustained editorial work
- Result of high cognitive load and judgment calls

**Solutions:**
1. **Take breaks:** Step away between reviews
2. **Vary work:** Alternate difficult and straightforward reviews
3. **Celebrate wins:** Note when authors improve
4. **Set boundaries:** Don't work excessive hours
5. **Connect with team:** Share challenges and successes
6. **Professional development:** Learn new skills, attend conferences
7. **Talk to supervisor:** May need workload adjustment or role variation

**Prevention:** Schedule regular variation in work (not just reviews all day every day).

**When to escalate:** If affecting work quality or personal wellbeing for more than 2 weeks.

---

## Support

- **Knowledge Base Questions:** See [ENGINEER_GUIDE.md](ENGINEER_GUIDE.md)
- **Author Questions:** See [AUTHOR_GUIDE.md](AUTHOR_GUIDE.md)
- **Production Questions:** See [PRODUCTION_GUIDE.md](PRODUCTION_GUIDE.md)
- **Style Guide:** HMH editorial standards
- **Technical Issues:** Create issue in GitHub

---

**Version:** 2.0 | **Last Updated:** November 6, 2025
**For more information:** See [README.md](README.md) | [USER_GUIDE.md](USER_GUIDE.md)
