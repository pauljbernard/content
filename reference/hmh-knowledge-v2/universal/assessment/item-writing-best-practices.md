# Item Writing Best Practices
**Quality Standards for Assessment Item Development**
**Scope:** Universal (all subjects and districts)
**Audience:** Curriculum developers and assessment authors

---

## Overview

**Quality assessment items** are clear, fair, aligned to standards, and measure what they intend to measure. Well-written items provide accurate information about student learning and support instructional decisions.

**Core Principle:** Every assessment item should have a clear purpose, measure a specific skill or knowledge, and be accessible to all students while maintaining rigor.

---

## Universal Item Writing Principles

### Principle 1: Alignment to Standards

**Every item must:**
- Align to specific learning standard (TEKS, CCSS, etc.)
- Match the DOK level of the standard
- Assess the skill/knowledge stated in standard
- Not require out-of-scope prerequisites

**Check:** Can you cite the exact standard and explain the alignment?

---

### Principle 2: Clear and Focused

**Every item must:**
- Have one clear correct answer (or defined set of answers)
- Measure one primary skill/concept
- Use clear, concise language
- Avoid ambiguity

**Check:** Would two experts agree on the correct answer?

---

### Principle 3: Accessible and Fair

**Every item must:**
- Use grade-appropriate language
- Avoid cultural bias
- Provide accommodations compatibility
- Follow CEID guidelines
- Minimize barriers unrelated to skill being measured

**Check:** Can all students access the content being assessed?

---

### Principle 4: Rigorous and Appropriate

**Every item must:**
- Match intended cognitive demand (DOK level)
- Challenge students appropriately
- Require true understanding (not tricks or gotchas)
- Measure meaningful learning

**Check:** Does this item assess important content, not trivia?

---

## Item Writing Guidelines by Type

### Multiple Choice (Single Select)

**Structure:**
- Stem (question or incomplete statement)
- Correct answer (key)
- 3-4 distractors (plausible wrong answers)

**Best Practices:**

**Stem:**
✅ **DO:**
- State a clear question or problem
- Include all necessary information
- Use positive phrasing when possible
- Put as much information in stem as possible (not in options)

❌ **DON'T:**
- Use negative phrasing unless essential ("Which is NOT...")
- Include irrelevant information
- Use vague stems ("Which is true about fractions?")

**Examples:**

✅ **Good Stem:**
"What is the area of a rectangle with length 6 cm and width 4 cm?"

❌ **Weak Stem:**
"Which of the following is correct?"

---

**Answer Choices:**

✅ **DO:**
- Make all options similar length and structure
- Use plausible distractors (common misconceptions)
- Order logically (numerical order, alphabetical, shortest to longest)
- Use parallel grammar

❌ **DON'T:**
- Give away answer with length (longest option is usually right)
- Use "all of the above" or "none of the above"
- Include joke options
- Use "A and B" or "B and C" options (use multiple response instead)

**Examples:**

✅ **Good Options:**
```
A. 10 cm
B. 20 cm
C. 24 cm
D. 30 cm
```
(Parallel structure, logical order, plausible)

❌ **Weak Options:**
```
A. 24 square centimeters (correct)
B. 10
C. Purple
D. All of the above
```
(Different formats, joke option, all/none)

---

**Distractors (Wrong Answers):**

**Effective Distractors:**
- Based on common misconceptions
- Result from predictable errors
- Plausible to students who don't fully understand
- Diagnostic (reveal thinking)

**Example (Area of Rectangle):**

Question: "What is the area of a rectangle with length 6 cm and width 4 cm?"

**A.** 20 cm (added instead of multiplied)
**B.** 24 cm² (perimeter instead of area)
**C.** 24 cm² ✓ **CORRECT**
**D.** 10 cm (only counted one dimension)

**Why These Distractors Work:**
- Each represents a common error
- Each is diagnostic of student thinking
- Each is plausible to students who partially understand

---

### Multiple Choice (Multiple Response)

**Structure:**
- Stem with question
- 4-6 options
- 2-4 correct answers (students select all that apply)

**Best Practices:**

✅ **DO:**
- Clearly state "Select all that apply" or "Choose all correct answers"
- Make number of correct answers non-obvious
- Ensure each option is independently true or false
- Provide partial credit option if appropriate

❌ **DON'T:**
- Make all options correct (or all wrong)
- Create dependencies between options
- Always have same number of correct answers

**Example:**

"Which of the following are factors of 24? Select all that apply."

☐ A. 2 ✓
☐ B. 5
☐ C. 6 ✓
☐ D. 7
☐ E. 8 ✓

**Scoring Options:**
- All-or-nothing: 1 point only if all three selected
- Partial credit: 0.5 points if 2 of 3 correct
- Point per correct: 0.33 points each (not recommended - too complex)

---

### Fill in the Blank (Short Answer)

**Best Practices:**

✅ **DO:**
- Be specific about required format
- Accept all equivalent answers
- Provide clear instructions
- Use auto-grading when possible (Learnosity equivSymbolic)

❌ **DON'T:**
- Require specific wording for concept answers
- Have multiple blanks that create ambiguity
- Expect students to read your mind

**Examples:**

✅ **Good:**
"What is the value of x? Round to the nearest tenth.
3x + 7 = 22
x = ___"

**Answer Key:** Accept 5, 5.0 (exact answer is 5)

❌ **Weak:**
"The quotient of 24 and 6 is ___."
(Is answer "4" or "the quotient"? Ambiguous.)

**Better:**
"24 ÷ 6 = ___"

---

### Constructed Response (Short Answer, Paragraph)

**Best Practices:**

✅ **DO:**
- Ask for specific type of response (explanation, example, justification)
- Provide clear success criteria
- Include rubric with item
- Give sufficient space/time
- Use task-specific rubric when possible

❌ **DON'T:**
- Ask multiple unrelated questions in one prompt
- Use vague prompts ("Explain your thinking" with no specificity)
- Expect essay-length responses for 2-point items

**Examples:**

✅ **Good Constructed Response (Math):**

"Solve: 3/4 + 1/8

Show your work and explain your strategy in 2-3 sentences."

**Rubric:**
- 2 points: Correct answer (7/8) with clear strategy shown and explained
- 1 point: Correct answer with work shown but no explanation, OR minor error with sound strategy
- 0 points: Incorrect answer with no valid strategy

❌ **Weak:**

"Solve 3/4 + 1/8 and explain how you did it and why this strategy works and when you would use it."

(Too many requirements for one item)

---

### Technology-Enhanced Items (TEI)

**Types:**
- Drag-and-drop
- Graphing/drawing
- Hot spot (click on image)
- Dropdown select
- Matching

**Best Practices:**

✅ **DO:**
- Provide keyboard alternative for drag-and-drop
- Test functionality thoroughly
- Ensure accessibility (screen reader compatible)
- Use when interaction enhances assessment
- Provide clear instructions (demos if complex)

❌ **DON'T:**
- Use technology for novelty alone
- Create items that only work with mouse
- Make interaction overly complex
- Sacrifice accessibility for interactivity

**Example:**

✅ **Good TEI:**
"Drag the fractions to the correct location on the number line."
+ Keyboard alternative: "Use arrow keys to select fraction, then use Tab and Enter to place."

❌ **Weak TEI:**
Interactive simulation with 10 steps just to answer a simple yes/no question.

**See Also:** `/universal/assessment/item-types-reference.md`

---

## Language and Accessibility

### Clear Language Principles:

**1. Use Grade-Appropriate Vocabulary**
- Match reading level to grade (don't over-complicate)
- Define or support technical terms
- Avoid idioms and colloquialisms unless that's what's being assessed

**Examples:**

✅ "Which equation shows the relationship?"
❌ "Which equation captures the essence of the interrelationship?"

---

**2. Minimize Unnecessary Language Complexity**
- Shorter sentences when possible
- Active voice preferred
- Direct language

**Examples:**

✅ "Solve for x: 2x + 5 = 13"
❌ "Given the algebraic equation presented below, determine the value that, when substituted for the variable x, would result in a true mathematical statement: 2x + 5 = 13"

---

**3. Avoid Cultural Bias**

**Check for:**
- Assumptions about experiences (vacations, sports, food)
- Name diversity
- Geographic diversity
- Socioeconomic assumptions

**Examples:**

❌ **Culturally Biased:**
"Maria's family went to Disneyland. If tickets cost $120 each for 4 people..."
(Assumes familiarity with Disneyland, assumes economic resources)

✅ **More Accessible:**
"A family bought 4 tickets to an event. Each ticket cost $120..."

**See Also:** `/universal/content-equity/ceid-guidelines.md`

---

**4. Support Emergent Bilinguals**

**Provide:**
- Visuals when helpful
- Context clues for vocabulary
- Simple, clear sentence structure
- Glossary for technical terms

**Examples:**

✅ **EB-Supportive:**
"What is the perimeter of this rectangle?
[Diagram with measurements labeled]
Perimeter = distance around the outside"

❌ **EB-Challenging:**
"Calculate the perimeter" (no visual, no definition)

**See Also:**
- `/universal/frameworks/eb-scaffolding-guide.md`
- Texas: `/districts/texas/language/elps-alignment.md`
- California: `/districts/california/language/eld-alignment.md`

---

## Item Alignment and DOK

### DOK Level Matching

**Every item should match the DOK level of the standard being assessed.**

**DOK 1 (Recall):**
- Recall facts, terms, definitions
- Recognize and identify

**Example:**
"What is 7 × 8?"
"Which of these is a prime number?"

---

**DOK 2 (Skill/Concept):**
- Apply a skill or concept
- Use information
- Follow procedures

**Example:**
"Solve: 3x + 7 = 22"
"What is the area of a rectangle with length 6 cm and width 4 cm?"

---

**DOK 3 (Strategic Thinking):**
- Explain reasoning
- Compare strategies
- Solve non-routine problems
- Justify

**Example:**
"Explain your strategy for solving 125 ÷ 5. Why does your method work?"
"Compare two methods for finding equivalent fractions. Which is more efficient? Why?"

---

**DOK 4 (Extended Thinking):**
- Multi-step problems across time
- Apply concepts to new situations
- Critique and synthesize

**Example:**
"Design an investigation to determine the relationship between the side length and perimeter of squares. Collect data, create a graph, and explain the pattern."

**See Also:** `/universal/frameworks/dok-framework.md`

---

### Checking Alignment

**Ask:**
1. What standard does this item assess?
2. What is the DOK level of that standard?
3. Does this item's cognitive demand match?
4. Does this item measure what the standard requires?

**Red Flags:**
- Standard requires explanation (DOK 3), but item is multiple choice recall (DOK 1)
- Standard is about fractions, but item requires advanced algebraic thinking not in standard
- Item measures reading comprehension when math standard is being assessed

---

## Answer Key Quality

### Every Item Needs:

**1. Correct Answer(s)**
- All acceptable forms listed
- Equivalent representations noted
- Units specified when required

**2. Distractor Rationale (for MCQ)**
- Why each wrong answer is wrong
- What misconception each represents
- Instructional implications

**3. Rubric (for Constructed Response)**
- 2-point, 1-point, 0-point criteria
- Sample responses at each level
- Clear scoring guidance

**4. Standard and DOK**
- Exact standard code
- DOK level
- Learning objective

**See Also:** `/universal/assessment/answer-key-standards.md`

---

## Item Review Checklist

### Before Publishing Any Item:

**Alignment:**
- [ ] Aligned to specific standard
- [ ] DOK level matches standard
- [ ] Measures intended skill/knowledge
- [ ] No out-of-scope prerequisites

**Language:**
- [ ] Clear and concise
- [ ] Grade-appropriate vocabulary
- [ ] Culturally unbiased
- [ ] Accessible to EBs with scaffolds

**Technical Quality:**
- [ ] One clear correct answer
- [ ] Distractors plausible and diagnostic (MCQ)
- [ ] All equivalent forms accepted (short answer)
- [ ] Rubric provided (constructed response)

**Accessibility:**
- [ ] Keyboard accessible (digital items)
- [ ] Alt text provided for images
- [ ] Screen reader compatible
- [ ] WCAG 2.1 AA compliant

**Fairness:**
- [ ] CEID guidelines followed
- [ ] Name diversity
- [ ] No stereotypes
- [ ] Equitable access

**Answer Key:**
- [ ] Complete and accurate
- [ ] Includes rationale (MCQ)
- [ ] Includes rubric (CR)
- [ ] Sample responses (when helpful)

---

## Common Item Writing Mistakes

### ❌ Mistake 1: Trick Questions

**Problem:** "Which is NOT a prime number: 2, 3, 5, 7?"

(All are prime - this is a gotcha, not assessment)

**Fix:** Assess understanding directly, not ability to avoid traps

---

### ❌ Mistake 2: Multiple Concepts in One Item

**Problem:** Item requires fractions, decimals, AND percentages when standard is only about fractions

**Fix:** Focus each item on one primary concept

---

### ❌ Mistake 3: Reading Comprehension Masquerading as Math

**Problem:**
"Jessica, who loves horseback riding and has two cats named Fluffy and Mr. Whiskers, went to the store on Tuesday after her piano lesson. She bought 3 apples at $0.50 each and 2 oranges at $0.75 each. After using a coupon for $0.25 off, what did she spend?"

**Fix:** Remove unnecessary language:
"Apples cost $0.50 each. Oranges cost $0.75 each. How much do 3 apples and 2 oranges cost?"

---

### ❌ Mistake 4: Answer Dependent on Previous Item

**Problem:**
"Question 5: What is 12 × 5?
Question 6: Now divide your answer from Question 5 by 3."

**Fix:** Make items independent or clearly scaffold if intentional

---

### ❌ Mistake 5: Vague Constructed Response Prompts

**Problem:** "Explain your thinking."

**Fix:** "Explain your strategy for solving this problem. Include the steps you took."

---

### ❌ Mistake 6: Options Give Away Answer

**Problem:**
"What is the area?
A. 24
B. 24 square units
C. 10 units
D. 20 square units"

(Option A obviously wrong - no units)

**Fix:** Parallel structure:
"A. 10 square units
B. 20 square units
C. 24 square units
D. 28 square units"

---

### ❌ Mistake 7: Culturally Biased Context

**Problem:** "At the country club, golf balls cost..."

**Fix:** "At a store, balls cost..." (accessible context)

---

### ❌ Mistake 8: Assessing Reading, Not Content

**Problem:** Grade 3 math item with Grade 6 reading level

**Fix:** Match reading level to grade, or provide visual support

---

## Item Writing Workflow

### Recommended Process:

**1. Identify Standard and DOK**
- Select specific standard to assess
- Note DOK level required
- Clarify what proficiency looks like

**2. Draft Item**
- Choose appropriate item type
- Write clear stem
- Create answer choices (MCQ) or rubric (CR)
- Include visual if helpful

**3. Write Answer Key**
- Specify correct answer(s)
- Write distractor rationale (MCQ)
- Create rubric with samples (CR)

**4. Self-Review**
- Use checklist above
- Check alignment
- Review for bias and accessibility

**5. Peer Review**
- Another author reviews
- Solve independently
- Provide feedback

**6. Revise**
- Address feedback
- Refine language
- Improve clarity

**7. Pilot Test (if possible)**
- Test with small group of students
- Analyze student responses
- Identify unexpected issues
- Revise as needed

**8. Publish**
- Add to item bank
- Tag with standard, DOK, difficulty
- Include complete answer key

---

## Subject-Specific Considerations

### Mathematics:

**Key Considerations:**
- Accept equivalent forms (fractions, decimals, percentages)
- Specify units when needed
- Provide visual models when helpful
- Avoid excessive language demands
- Include real-world contexts

**Common Item Types:**
- Multiple choice (procedures, concepts)
- Short answer (numerical)
- Constructed response (explain strategy)

**See Also:** MLR integration for language support

---

### ELA:

**Key Considerations:**
- Text-dependent questions (require evidence)
- Match text complexity to grade level
- Balance literal and inferential
- Provide rubrics for writing

**Common Item Types:**
- Multiple choice (comprehension, vocabulary)
- Constructed response (analysis, theme)
- Extended response (essay)

**See Also:** Close Reading Protocol, literacy routines

---

### Science:

**Key Considerations:**
- Assess science, not just vocabulary
- Include diagrams and visuals
- Require evidence-based reasoning
- Real-world applications

---

## Digital Assessment Considerations

### Learnosity-Specific:

**Configuration:**
- Use equivSymbolic for math equivalents
- Enable accessibility features
- Test on multiple devices
- Verify auto-scoring logic

**Item Types:**
- Test interactive features thoroughly
- Provide keyboard alternatives
- Ensure mobile compatibility

**See Also:** `/universal/assessment/learnosity-configuration-guide.md`

---

## Resources

**Related Guides:**
- Answer Key Standards: `/universal/assessment/answer-key-standards.md`
- Item Types Reference: `/universal/assessment/item-types-reference.md`
- Scoring Rubrics: `/universal/assessment/scoring-rubrics-guide.md`
- DOK Framework: `/universal/frameworks/dok-framework.md`
- CEID Guidelines: `/universal/content-equity/ceid-guidelines.md`
- EB Scaffolding: `/universal/frameworks/eb-scaffolding-guide.md`
- WCAG Compliance: `/universal/accessibility/wcag-compliance-guide.md`

**Subject-Specific:**
- Math MLRs: `/subjects/mathematics/common/mlr/`
- ELA Literacy Routines: `/subjects/ela/common/literacy-routines/`

---

**Remember:** Quality items are clear, fair, aligned, and accessible. Every item should have a purpose and measure what it intends to measure. Write items that provide useful information about student learning, not puzzles or tricks. When students miss an item, you should know exactly what they don't understand yet. Good assessment drives good instruction.
